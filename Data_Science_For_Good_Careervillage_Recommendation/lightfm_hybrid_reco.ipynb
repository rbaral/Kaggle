{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Overview: \n",
    "\n",
    "This notebook contains a solution for Career village recommendation system competition. In this notebook, I build a hybrid recommendation system for recommending students questions to professionals for CareerVillage.org. The recommender system works by matching professionals with questions by tags they follow, their previous answers' question tags and similar tags. Also, it overcomes some of the most highest rated problem for CareerVillage recommender system like cold-start and others.\n",
    "\n",
    "# Competition problem statements: \n",
    "    \n",
    "CareerVillage.org is a non-profit organization helping underserved youth to provide information to build their career. Students can ask their questions in the CareerVillage.org and professionals(expert people who love to help students) answer their questions. The challenge is that CareerVillage has to recommend correct questions to the professionals so that the questions match with the professional's interests. This will increase the likelihood of a question to get an answer. So in this competition, we have to make a recommendation system that will correctly recommend questions that will match with professionals interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dur-rbaral-m/opt/anaconda3/lib/python3.7/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn('LightFM was compiled without OpenMP support. '\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "# Importing necessary library\n",
    "################################################\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# all lightfm imports \n",
    "from lightfm.data import Dataset\n",
    "from lightfm import LightFM\n",
    "from lightfm import cross_validation\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from lightfm.evaluation import auc_score\n",
    "\n",
    "# imports re for text cleaning \n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# we will ignore pandas warning \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Read all our datasets and store them in pandas dataframe objects. \n",
    "############################################\n",
    "base_path = '../../../data/data-science-for-good-careervillage/'\n",
    "df_answer_scores = pd.read_csv(\n",
    "    base_path + 'answer_scores.csv')\n",
    "\n",
    "df_answers = pd.read_csv(\n",
    "    base_path + 'answers.csv',\n",
    "    parse_dates=['answers_date_added'])\n",
    "\n",
    "df_comments = pd.read_csv(\n",
    "    base_path + 'comments.csv')\n",
    "\n",
    "df_emails = pd.read_csv(\n",
    "    base_path + 'emails.csv')\n",
    "\n",
    "df_group_memberships = pd.read_csv(\n",
    "    base_path + 'group_memberships.csv')\n",
    "\n",
    "df_groups = pd.read_csv(\n",
    "    base_path + 'groups.csv')\n",
    "\n",
    "df_matches = pd.read_csv(\n",
    "    base_path + 'matches.csv')\n",
    "\n",
    "df_professionals = pd.read_csv(\n",
    "    base_path + 'professionals.csv',\n",
    "    parse_dates=['professionals_date_joined'])\n",
    "\n",
    "df_question_scores = pd.read_csv(\n",
    "    base_path + 'question_scores.csv')\n",
    "\n",
    "df_questions = pd.read_csv(\n",
    "    base_path + 'questions.csv',\n",
    "    parse_dates=['questions_date_added'])\n",
    "\n",
    "df_school_memberships = pd.read_csv(\n",
    "    base_path + 'school_memberships.csv')\n",
    "\n",
    "df_students = pd.read_csv(\n",
    "    base_path + 'students.csv',\n",
    "    parse_dates=['students_date_joined'])\n",
    "\n",
    "df_tag_questions = pd.read_csv(\n",
    "    base_path + 'tag_questions.csv')\n",
    "\n",
    "df_tag_users = pd.read_csv(\n",
    "    base_path + 'tag_users.csv')\n",
    "\n",
    "df_tags = pd.read_csv(\n",
    "    base_path + 'tags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_int_id(dataframe, id_col_name):\n",
    "    \"\"\"\n",
    "    Generate unique integer id for users, questions and answers\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe: Dataframe\n",
    "        Pandas Dataframe for Users or Q&A. \n",
    "    id_col_name : String \n",
    "        New integer id's column name.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Dataframe\n",
    "        Updated dataframe containing new id column \n",
    "    \"\"\"\n",
    "    new_dataframe=dataframe.assign(\n",
    "        int_id_col_name=np.arange(len(dataframe))\n",
    "        ).reset_index(drop=True)\n",
    "    return new_dataframe.rename(columns={'int_id_col_name': id_col_name})\n",
    "\n",
    "\n",
    "\n",
    "def create_features(dataframe, features_name, id_col_name):\n",
    "    \"\"\"\n",
    "    Generate features that will be ready for feeding into lightfm\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe: Dataframe\n",
    "        Pandas Dataframe which contains features\n",
    "    features_name : List\n",
    "        List of feature columns name avaiable in dataframe\n",
    "    id_col_name: String\n",
    "        Column name which contains id of the question or\n",
    "        answer that the features will map to.\n",
    "        There are two possible values for this variable.\n",
    "        1. questions_id_num\n",
    "        2. professionals_id_num\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Pandas Series\n",
    "        A pandas series containing process features\n",
    "        that are ready for feed into lightfm.\n",
    "        The format of each value\n",
    "        will be (user_id, ['feature_1', 'feature_2', 'feature_3'])\n",
    "        Ex. -> (1, ['military', 'army', '5'])\n",
    "    \"\"\"\n",
    "\n",
    "    features = dataframe[features_name].apply(\n",
    "        lambda x: ','.join(x.map(str)), axis=1)\n",
    "    features = features.str.split(',')\n",
    "    features = list(zip(dataframe[id_col_name], features))\n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "def generate_feature_list(dataframe, features_name):\n",
    "    \"\"\"\n",
    "    Generate features list for mapping \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe: Dataframe\n",
    "        Pandas Dataframe for Users or Q&A. \n",
    "    features_name : List\n",
    "        List of feature columns name avaiable in dataframe. \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    List of all features for mapping \n",
    "    \"\"\"\n",
    "    features = dataframe[features_name].apply(\n",
    "        lambda x: ','.join(x.map(str)), axis=1)\n",
    "    features = features.str.split(',')\n",
    "    features = features.apply(pd.Series).stack().reset_index(drop=True)\n",
    "    return features\n",
    "\n",
    "\n",
    "def calculate_auc_score(lightfm_model, interactions_matrix, \n",
    "                        question_features, professional_features): \n",
    "    \"\"\"\n",
    "    Measure the ROC AUC metric for a model. \n",
    "    A perfect score is 1.0.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lightfm_model: LightFM model \n",
    "        A fitted lightfm model \n",
    "    interactions_matrix : \n",
    "        A lightfm interactions matrix \n",
    "    question_features, professional_features: \n",
    "        Lightfm features \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    String containing AUC score \n",
    "    \"\"\"\n",
    "    score = auc_score( \n",
    "        lightfm_model, interactions_matrix, \n",
    "        item_features=question_features, \n",
    "        user_features=professional_features, \n",
    "        num_threads=4).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating unique integer id for users and q&a\n",
    "df_professionals = generate_int_id(df_professionals, 'professionals_id_num')\n",
    "df_students = generate_int_id(df_students, 'students_id_num')\n",
    "df_questions = generate_int_id(df_questions, 'questions_id_num')\n",
    "df_answers = generate_int_id(df_answers, 'answers_id_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# merging dataset\n",
    "###########################\n",
    "\n",
    "# just dropna from tags \n",
    "df_tags = df_tags.dropna()\n",
    "df_tags['tags_tag_name'] = df_tags['tags_tag_name'].str.replace('#', '')\n",
    "\n",
    "\n",
    "# merge tag_questions with tags name\n",
    "# then group all tags for each question into single rows\n",
    "df_tags_question = df_tag_questions.merge(\n",
    "    df_tags, how='inner',\n",
    "    left_on='tag_questions_tag_id', right_on='tags_tag_id')\n",
    "df_tags_question = df_tags_question.groupby(\n",
    "    ['tag_questions_question_id'])['tags_tag_name'].apply(\n",
    "        ','.join).reset_index()\n",
    "df_tags_question = df_tags_question.rename(columns={'tags_tag_name': 'questions_tag_name'})\n",
    "\n",
    "# merge tag_users with tags name \n",
    "# then group all tags for each user into single rows \n",
    "# after that rename the tag column name \n",
    "df_tags_pro = df_tag_users.merge(\n",
    "    df_tags, how='inner',\n",
    "    left_on='tag_users_tag_id', right_on='tags_tag_id')\n",
    "df_tags_pro = df_tags_pro.groupby(\n",
    "    ['tag_users_user_id'])['tags_tag_name'].apply(\n",
    "        ','.join).reset_index()\n",
    "df_tags_pro = df_tags_pro.rename(columns={'tags_tag_name': 'professionals_tag_name'})\n",
    "\n",
    "\n",
    "# merge professionals and questions tags with main merge_dataset \n",
    "df_questions = df_questions.merge(\n",
    "    df_tags_question, how='left',\n",
    "    left_on='questions_id', right_on='tag_questions_question_id')\n",
    "df_professionals = df_professionals.merge(\n",
    "    df_tags_pro, how='left',\n",
    "    left_on='professionals_id', right_on='tag_users_user_id')\n",
    "\n",
    "# merge questions with scores \n",
    "df_questions = df_questions.merge(\n",
    "    df_question_scores, how='left',\n",
    "    left_on='questions_id', right_on='id')\n",
    "# merge questions with students \n",
    "df_questions = df_questions.merge(\n",
    "    df_students, how='left',\n",
    "    left_on='questions_author_id', right_on='students_id')\n",
    "\n",
    "\n",
    "\n",
    "# merge answers with questions \n",
    "# then merge professionals and questions score with that \n",
    "df_merge = df_answers.merge(\n",
    "    df_questions, how='inner',\n",
    "    left_on='answers_question_id', right_on='questions_id')\n",
    "df_merge = df_merge.merge(\n",
    "    df_professionals, how='inner',\n",
    "    left_on='answers_author_id', right_on='professionals_id')\n",
    "df_merge = df_merge.merge(\n",
    "    df_question_scores, how='inner',\n",
    "    left_on='questions_id', right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "# Generate some features for calculates weights\n",
    "# that will use with interaction matrix \n",
    "#######################\n",
    "\n",
    "df_merge['num_of_ans_by_professional'] = df_merge.groupby(['answers_author_id'])['questions_id'].transform('count')\n",
    "df_merge['num_ans_per_ques'] = df_merge.groupby(['questions_id'])['answers_id'].transform('count')\n",
    "df_merge['num_tags_professional'] = df_merge['professionals_tag_name'].str.split(\",\").str.len()\n",
    "df_merge['num_tags_question'] = df_merge['questions_tag_name'].str.split(\",\").str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of answer per question : 58\n",
      "Maximum number of tags per professional : 82.0\n",
      "Maximum number of tags per question : 54.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximum number of answer per question : \" + str(df_merge['num_ans_per_ques'].max()))\n",
    "print(\"Maximum number of tags per professional : \" + str(df_merge['num_tags_professional'].max()))\n",
    "print(\"Maximum number of tags per question : \" + str(df_merge['num_tags_question'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "#Merge answered questions tags with professional's tags: Professionals can follow some tags. \n",
    "#But not all professional follow tags and most especially we see from EDA that sometime professionals \n",
    "#answers questions that is not related to their tags. For that reason, I have merge questions tags that \n",
    "#each professional has answered with professional tags. \n",
    "#This makes our model more robust and context aware.\n",
    "\n",
    "# Merge professionals previous answered \n",
    "# questions tags into professionals tags \n",
    "########################\n",
    "\n",
    "# select professionals answered questions tags \n",
    "# and stored as a dataframe\n",
    "professionals_prev_ans_tags = df_merge[['professionals_id', 'questions_tag_name']]\n",
    "# drop null values from that \n",
    "professionals_prev_ans_tags = professionals_prev_ans_tags.dropna()\n",
    "# because professsionals answers multiple questions, \n",
    "# we group all of tags of each user into single row \n",
    "professionals_prev_ans_tags = professionals_prev_ans_tags.groupby(\n",
    "    ['professionals_id'])['questions_tag_name'].apply(\n",
    "        ','.join).reset_index()\n",
    "\n",
    "# drop duplicates tags from each professionals rows\n",
    "professionals_prev_ans_tags['questions_tag_name'] = (\n",
    "    professionals_prev_ans_tags['questions_tag_name'].str.split(',').apply(set).str.join(','))\n",
    "\n",
    "# finally merge the dataframe with professionals dataframe \n",
    "df_professionals = df_professionals.merge(professionals_prev_ans_tags, how='left', on='professionals_id')\n",
    "\n",
    "# join professionals tags and their answered tags \n",
    "# we replace nan values with \"\"\n",
    "df_professionals['professional_all_tags'] = (\n",
    "    df_professionals[['professionals_tag_name', 'questions_tag_name']].apply(\n",
    "        lambda x: ','.join(x.dropna()),\n",
    "        axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling null values and duplicates\n",
    "df_questions['score'] = df_questions['score'].fillna(0)\n",
    "df_questions['score'] = df_questions['score'].astype(int)\n",
    "df_questions['questions_tag_name'] = df_questions['questions_tag_name'].fillna('No Tag')\n",
    "# remove duplicates tags from each questions \n",
    "df_questions['questions_tag_name'] = df_questions['questions_tag_name'].str.split(',').apply(set).str.join(',')\n",
    "\n",
    "\n",
    "# fill nan with 'No Tag' if any \n",
    "df_professionals['professional_all_tags'] = df_professionals['professional_all_tags'].fillna('No Tag')\n",
    "# replace \"\" with \"No Tag\", because previously we replace nan with \"\"\n",
    "df_professionals['professional_all_tags'] = df_professionals['professional_all_tags'].replace('', 'No Tag')\n",
    "df_professionals['professionals_location'] = df_professionals['professionals_location'].fillna('No Location')\n",
    "df_professionals['professionals_industry'] = df_professionals['professionals_industry'].fillna('No Industry')\n",
    "\n",
    "# remove duplicates tags from each professionals \n",
    "df_professionals['professional_all_tags'] = df_professionals['professional_all_tags'].str.split(',').apply(set).str.join(',')\n",
    "\n",
    "\n",
    "\n",
    "# remove some null values from df_merge\n",
    "df_merge['num_ans_per_ques']  = df_merge['num_ans_per_ques'].fillna(0)\n",
    "df_merge['num_tags_professional'] = df_merge['num_tags_professional'].fillna(0)\n",
    "df_merge['num_tags_question'] = df_merge['num_tags_question'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating features list for mapping \n",
    "question_feature_list = generate_feature_list(\n",
    "    df_questions,\n",
    "    ['questions_tag_name'])\n",
    "\n",
    "professional_feature_list = generate_feature_list(\n",
    "    df_professionals,\n",
    "    ['professional_all_tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate our weight value \n",
    "df_merge['total_weights'] = 1 / (\n",
    "    df_merge['num_ans_per_ques'])\n",
    "\n",
    "\n",
    "# creating features for feeding into lightfm \n",
    "df_questions['question_features'] = create_features(\n",
    "    df_questions, ['questions_tag_name'], \n",
    "    'questions_id_num')\n",
    "\n",
    "df_professionals['professional_features'] = create_features(\n",
    "    df_professionals,\n",
    "    ['professional_all_tags'],\n",
    "    'professionals_id_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Dataset building for lightfm\n",
    "########################\n",
    "\n",
    "# define our dataset variable\n",
    "# then we feed unique professionals and questions ids\n",
    "# and item and professional feature list\n",
    "# this will create lightfm internel mapping\n",
    "dataset = Dataset()\n",
    "dataset.fit(\n",
    "    set(df_professionals['professionals_id_num']), \n",
    "    set(df_questions['questions_id_num']),\n",
    "    item_features=question_feature_list, \n",
    "    user_features=professional_feature_list)\n",
    "\n",
    "\n",
    "# now we are building interactions matrix between professionals and quesitons\n",
    "# we are passing professional and questions id as a tuple\n",
    "# e.g -> pd.Series((pro_id, question_id), (pro_id, questin_id))\n",
    "# then we use lightfm build in method for building interactions matrix\n",
    "df_merge['author_question_id_tuple'] = list(zip(\n",
    "    df_merge.professionals_id_num, df_merge.questions_id_num, df_merge.total_weights))\n",
    "\n",
    "interactions, weights = dataset.build_interactions(\n",
    "    df_merge['author_question_id_tuple'])\n",
    "\n",
    "\n",
    "\n",
    "# now we are building our questions and professionals features\n",
    "# in a way that lightfm understand.\n",
    "# we are using lightfm build in method for building\n",
    "# questions and professionals features \n",
    "questions_features = dataset.build_item_features(\n",
    "    df_questions['question_features'])\n",
    "\n",
    "professional_features = dataset.build_user_features(\n",
    "    df_professionals['professional_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x1a2d334e50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################\n",
    "# Model building part\n",
    "################################\n",
    "\n",
    "# define lightfm model by specifying hyper-parametre\n",
    "# then fit the model with ineteractions matrix, item and user features \n",
    "model = LightFM(\n",
    "    no_components=150,\n",
    "    learning_rate=0.05,\n",
    "    loss='warp',\n",
    "    random_state=2019)\n",
    "\n",
    "model.fit(\n",
    "    interactions,\n",
    "    item_features=questions_features,\n",
    "    user_features=professional_features, sample_weight=weights,\n",
    "    epochs=5, num_threads=4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91337264"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_auc_score(model, interactions, questions_features, professional_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make real recommendations\n",
    "from IPython.display import display_html\n",
    "def display_side_by_side(*args):\n",
    "    html_str=''\n",
    "    for df in args:\n",
    "        html_str+=df.to_html()\n",
    "    display_html(html_str.replace('table','table style=\"display:inline\"'),raw=True)\n",
    "\n",
    "def recommend_questions(professional_ids):\n",
    "     \n",
    "    for professional in professional_ids:\n",
    "        # print their previous answered question title\n",
    "        previous_q_id_num = df_merge.loc[df_merge['professionals_id_num'] == professional][:3]['questions_id_num']\n",
    "        df_previous_questions = df_questions.loc[df_questions['questions_id_num'].isin(previous_q_id_num)]\n",
    "        print('Professional Id (' + str(professional) + \"): Previous Answered Questions\")\n",
    "        display_side_by_side(\n",
    "            df_previous_questions[['questions_title', 'question_features']],\n",
    "            df_professionals.loc[df_professionals.professionals_id_num == professional][['professionals_id_num','professionals_tag_name']])\n",
    "        \n",
    "        # predict\n",
    "        discard_qu_id = df_previous_questions['questions_id_num'].values.tolist()\n",
    "        df_use_for_prediction = df_questions.loc[~df_questions['questions_id_num'].isin(discard_qu_id)]\n",
    "        questions_id_for_predict = df_use_for_prediction['questions_id_num'].values.tolist()\n",
    "        \n",
    "        scores = model.predict(\n",
    "            professional,\n",
    "            questions_id_for_predict,\n",
    "            item_features=questions_features,\n",
    "            user_features=professional_features)\n",
    "        \n",
    "        df_use_for_prediction['scores'] = scores\n",
    "        df_use_for_prediction = df_use_for_prediction.sort_values(by='scores', ascending=False)[:8]\n",
    "        print('Professional Id (' + str(professional) + \"): Recommended Questions: \")\n",
    "        display(df_use_for_prediction[['questions_title', 'question_features']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professional Id (1200): Previous Answered Questions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions_title</th>\n",
       "      <th>question_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>professionals_id_num</th>\n",
       "      <th>professionals_tag_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>1200</td>\n",
       "      <td>marketing,strategy,entrepreneurship,management,java,advertising,python,data-analysis,online-advertising,real-estate,team-leadership,dj,analytics,display-advertising,football,blackjack,hip-hop,billiards,break</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professional Id (1200): Recommended Questions: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions_title</th>\n",
       "      <th>question_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>19011</td>\n",
       "      <td>How do you get started in starting your own bu...</td>\n",
       "      <td>(19011, [business, marketing, management])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8559</td>\n",
       "      <td>Which Business field of study is best suited t...</td>\n",
       "      <td>(8559, [administration, entrepreneurship, busi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14451</td>\n",
       "      <td>What is the best way to find a good internship...</td>\n",
       "      <td>(14451, [business, marketing])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23680</td>\n",
       "      <td>what makes markerting so important in business?</td>\n",
       "      <td>(23680, [business, marketing])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15671</td>\n",
       "      <td>How beneficial will a business major be ?</td>\n",
       "      <td>(15671, [business, finance, accounting, market...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10073</td>\n",
       "      <td>How important is a business degree when trying...</td>\n",
       "      <td>(10073, [business, entrepreneurship])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9867</td>\n",
       "      <td>Best way to get started in entrepreneurship an...</td>\n",
       "      <td>(9867, [business, entrepreneurship])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15730</td>\n",
       "      <td>What does it take to succeed in business?</td>\n",
       "      <td>(15730, [business, entrepreneurship])</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         questions_title  \\\n",
       "19011  How do you get started in starting your own bu...   \n",
       "8559   Which Business field of study is best suited t...   \n",
       "14451  What is the best way to find a good internship...   \n",
       "23680    what makes markerting so important in business?   \n",
       "15671          How beneficial will a business major be ?   \n",
       "10073  How important is a business degree when trying...   \n",
       "9867   Best way to get started in entrepreneurship an...   \n",
       "15730          What does it take to succeed in business?   \n",
       "\n",
       "                                       question_features  \n",
       "19011         (19011, [business, marketing, management])  \n",
       "8559   (8559, [administration, entrepreneurship, busi...  \n",
       "14451                     (14451, [business, marketing])  \n",
       "23680                     (23680, [business, marketing])  \n",
       "15671  (15671, [business, finance, accounting, market...  \n",
       "10073              (10073, [business, entrepreneurship])  \n",
       "9867                (9867, [business, entrepreneurship])  \n",
       "15730              (15730, [business, entrepreneurship])  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professional Id (19897): Previous Answered Questions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions_title</th>\n",
       "      <th>question_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22784</th>\n",
       "      <td>Do companies truly focus on your college major when applying for jobs?</td>\n",
       "      <td>(22784, [major])</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>professionals_id_num</th>\n",
       "      <th>professionals_tag_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19897</th>\n",
       "      <td>19897</td>\n",
       "      <td>illustration,graphic-design,adobe-creative-suite,comic-books</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professional Id (19897): Recommended Questions: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions_title</th>\n",
       "      <th>question_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>19407</td>\n",
       "      <td>How can you be a successful photographer? What...</td>\n",
       "      <td>(19407, [art, photography, graphic-design])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2310</td>\n",
       "      <td>what is one of best things about being an anim...</td>\n",
       "      <td>(2310, [animation, art, design, artist])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9682</td>\n",
       "      <td>How to get started in animation?</td>\n",
       "      <td>(9682, [animation, art, artist])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6058</td>\n",
       "      <td>How should you start in the Graphic Design ind...</td>\n",
       "      <td>(6058, [art, design, graphic-design])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23691</td>\n",
       "      <td>How to comopose/write music without going ti s...</td>\n",
       "      <td>(23691, [music, art])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13484</td>\n",
       "      <td>Would a Graphic Design degree be a feesible op...</td>\n",
       "      <td>(13484, [art, graphic-design])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1416</td>\n",
       "      <td>Is Competition In The Animation Field Low or H...</td>\n",
       "      <td>(1416, [animation, art])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19471</td>\n",
       "      <td>Graphic Design - job outlook for the next 10 y...</td>\n",
       "      <td>(19471, [art, graphic-design])</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         questions_title  \\\n",
       "19407  How can you be a successful photographer? What...   \n",
       "2310   what is one of best things about being an anim...   \n",
       "9682                    How to get started in animation?   \n",
       "6058   How should you start in the Graphic Design ind...   \n",
       "23691  How to comopose/write music without going ti s...   \n",
       "13484  Would a Graphic Design degree be a feesible op...   \n",
       "1416   Is Competition In The Animation Field Low or H...   \n",
       "19471  Graphic Design - job outlook for the next 10 y...   \n",
       "\n",
       "                                 question_features  \n",
       "19407  (19407, [art, photography, graphic-design])  \n",
       "2310      (2310, [animation, art, design, artist])  \n",
       "9682              (9682, [animation, art, artist])  \n",
       "6058         (6058, [art, design, graphic-design])  \n",
       "23691                        (23691, [music, art])  \n",
       "13484               (13484, [art, graphic-design])  \n",
       "1416                      (1416, [animation, art])  \n",
       "19471               (19471, [art, graphic-design])  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professional Id (3): Previous Answered Questions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions_title</th>\n",
       "      <th>question_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11339</th>\n",
       "      <td>What are the different jobs a person can do in Forensic Science?</td>\n",
       "      <td>(11339, [criminal, justice, forensic, science])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14818</th>\n",
       "      <td>What does a typical work day for a forensic scientist look like?</td>\n",
       "      <td>(14818, [No Tag])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19077</th>\n",
       "      <td>Is most of your day spent working when being a detective?</td>\n",
       "      <td>(19077, [detective])</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>professionals_id_num</th>\n",
       "      <th>professionals_tag_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professional Id (3): Recommended Questions: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions_title</th>\n",
       "      <th>question_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2423</td>\n",
       "      <td>How long does it take to become a Detective?</td>\n",
       "      <td>(2423, [law, criminal-justice, police, law-enf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17184</td>\n",
       "      <td>What types of Detectives are there?</td>\n",
       "      <td>(17184, [law, criminal-justice, police, law-en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9778</td>\n",
       "      <td>I want to be a police officer or a police disp...</td>\n",
       "      <td>(9778, [law, criminal-justice, police, law-enf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8863</td>\n",
       "      <td>What qualifications are needed to be promoted ...</td>\n",
       "      <td>(8863, [criminal-justice, law-enforcement, pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11514</td>\n",
       "      <td>What does an aspiring cop have to look forward...</td>\n",
       "      <td>(11514, [criminal-justice, law-enforcement, po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1936</td>\n",
       "      <td>What degrees do you have to have in order to g...</td>\n",
       "      <td>(1936, [criminal-justice, law-enforcement, pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18947</td>\n",
       "      <td>Could I go straight into Law Enforcememt, when...</td>\n",
       "      <td>(18947, [law, law-enforcement, police])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20003</td>\n",
       "      <td>how many criminal psychologist jobs are our th...</td>\n",
       "      <td>(20003, [criminal-justice, psychology, law-enf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         questions_title  \\\n",
       "2423        How long does it take to become a Detective?   \n",
       "17184                What types of Detectives are there?   \n",
       "9778   I want to be a police officer or a police disp...   \n",
       "8863   What qualifications are needed to be promoted ...   \n",
       "11514  What does an aspiring cop have to look forward...   \n",
       "1936   What degrees do you have to have in order to g...   \n",
       "18947  Could I go straight into Law Enforcememt, when...   \n",
       "20003  how many criminal psychologist jobs are our th...   \n",
       "\n",
       "                                       question_features  \n",
       "2423   (2423, [law, criminal-justice, police, law-enf...  \n",
       "17184  (17184, [law, criminal-justice, police, law-en...  \n",
       "9778   (9778, [law, criminal-justice, police, law-enf...  \n",
       "8863   (8863, [criminal-justice, law-enforcement, pol...  \n",
       "11514  (11514, [criminal-justice, law-enforcement, po...  \n",
       "1936   (1936, [criminal-justice, law-enforcement, pol...  \n",
       "18947            (18947, [law, law-enforcement, police])  \n",
       "20003  (20003, [criminal-justice, psychology, law-enf...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recommend_questions([1200 ,19897, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "Analysis: Awesome! Finally we can see our recommendation by our model. Let's take some time to ponder over the recommendations.\n",
    "\n",
    "For the first professionl (1200) has not answer any questions yet. But he/she follows some tags. Our model take those tags as features and predict questions that has similar tags.\n",
    "For the second professionals (19897) answered one questions that has tag major. But in his profile he follows tags like creative works like arts, illustrator etc. So our model recommend questions that has creative tags like arts, illustrator because he follows more tags one creative works.\n",
    "For the third professionals (3): answered questions that has tag forensic, criminal, science, justice, detective. From the tags we can get an idea of professionals interests. Our model also learn that. That's why it recommend items that has tags like law, criminal, detective.\n",
    "This is just a simple exploration. Hope you get idea of the model recommendations. The model can survive cold-start, high-poularity problem. It also recommend those questions that has less answer because of its weights that I provided during training. Now we build our model and tested it. In the next section, we will look how we can put this model in production.\n",
    "\n",
    "# Model in production\n",
    "\n",
    "Well, now we are going build a pipeline that will help us for putting this model into production. We are going to build class for each steps discuss in step 2. Also, we are going to build some additional functions and methods that will add additional functionality to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Read all our datasets agian \n",
    "# and store them in pandas dataframe objects. \n",
    "############################################\n",
    "base_path = '../../../data/data-science-for-good-careervillage/'\n",
    "df_answer_scores = pd.read_csv(\n",
    "    base_path + 'answer_scores.csv')\n",
    "\n",
    "df_answers = pd.read_csv(\n",
    "    base_path + 'answers.csv',\n",
    "    parse_dates=['answers_date_added'])\n",
    "\n",
    "df_comments = pd.read_csv(\n",
    "    base_path + 'comments.csv')\n",
    "\n",
    "df_emails = pd.read_csv(\n",
    "    base_path + 'emails.csv')\n",
    "\n",
    "df_group_memberships = pd.read_csv(\n",
    "    base_path + 'group_memberships.csv')\n",
    "\n",
    "df_groups = pd.read_csv(\n",
    "    base_path + 'groups.csv')\n",
    "\n",
    "df_matches = pd.read_csv(\n",
    "    base_path + 'matches.csv')\n",
    "\n",
    "df_professionals = pd.read_csv(\n",
    "    base_path + 'professionals.csv',\n",
    "    parse_dates=['professionals_date_joined'])\n",
    "\n",
    "df_question_scores = pd.read_csv(\n",
    "    base_path + 'question_scores.csv')\n",
    "\n",
    "df_questions = pd.read_csv(\n",
    "    base_path + 'questions.csv',\n",
    "    parse_dates=['questions_date_added'])\n",
    "\n",
    "df_school_memberships = pd.read_csv(\n",
    "    base_path + 'school_memberships.csv')\n",
    "\n",
    "df_students = pd.read_csv(\n",
    "    base_path + 'students.csv',\n",
    "    parse_dates=['students_date_joined'])\n",
    "\n",
    "df_tag_questions = pd.read_csv(\n",
    "    base_path + 'tag_questions.csv')\n",
    "\n",
    "df_tag_users = pd.read_csv(\n",
    "    base_path + 'tag_users.csv')\n",
    "\n",
    "df_tags = pd.read_csv(\n",
    "    base_path + 'tags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CareerVillageDataPreparation:\n",
    "    \"\"\"\n",
    "    Clean and process data CareerVillage Data. \n",
    "    \n",
    "    This class process data in a way that will be useful\n",
    "    for building lightFM dataset. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def _assign_unique_id(self, data, id_col_name):\n",
    "        \"\"\"\n",
    "        Generate unique integer id for users, questions and answers\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data: Dataframe\n",
    "            Pandas Dataframe for Users or Q&A. \n",
    "        id_col_name : String \n",
    "            New integer id's column name.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Dataframe\n",
    "            Updated dataframe containing new id column\n",
    "        \"\"\"\n",
    "        new_dataframe=data.assign(\n",
    "            int_id_col_name=np.arange(len(data))\n",
    "            ).reset_index(drop=True)\n",
    "        return new_dataframe.rename(columns={'int_id_col_name': id_col_name})\n",
    "\n",
    "    def _dropna(self, data, column, axis):\n",
    "        \"\"\"Drop null values from specific column\"\"\"\n",
    "        return data.dropna(column, axis=axis)\n",
    "\n",
    "    def _merge_data(self, left_data, left_key, right_data, right_key, how):\n",
    "        \"\"\"\n",
    "        This function is used for merging two dataframe.\n",
    "        \n",
    "        Parameters\n",
    "        -----------\n",
    "        left_data: Dataframe\n",
    "            Left side dataframe for merge\n",
    "        left_key: String\n",
    "            Left Dataframe merge key\n",
    "        right_data: Dataframe\n",
    "            Right side dataframe for merge\n",
    "        right_key: String\n",
    "            Right Dataframe merge key\n",
    "        how: String\n",
    "            Method of merge (inner, left, right, outer)\n",
    "            \n",
    "        \n",
    "        Returns\n",
    "        --------\n",
    "        Dataframe\n",
    "            A new dataframe merging left and right dataframe\n",
    "        \"\"\"\n",
    "        return left_data.merge(\n",
    "            right_data,\n",
    "            how=how,\n",
    "            left_on=left_key,\n",
    "            right_on=right_key)\n",
    "\n",
    "    def _group_tags(self, data, group_by, tag_column):\n",
    "        \"\"\"Grouop multiple tags into single rows sepearated by comma\"\"\"\n",
    "        return data.groupby(\n",
    "            [group_by])[tag_column].apply(\n",
    "            ','.join).reset_index()\n",
    "\n",
    "    def _merge_cv_datasets(\n",
    "        self,\n",
    "        professionals,students,\n",
    "        questions,answers,\n",
    "        tags,tag_questions,tag_users, questions_score):\n",
    "        \"\"\"\n",
    "        This function merges all the necessary \n",
    "        CareerVillage dataset in defined way. \n",
    "        \n",
    "        Parameters\n",
    "        ------------\n",
    "        professionals,students,\n",
    "        questions,answers,\n",
    "        tags,tag_questions,\n",
    "        tag_users,\n",
    "        questions_score: Dataframe\n",
    "            Pandas dataframe defined by it's name\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        ---------\n",
    "        questions, professionals: Dataframe\n",
    "            Updated dataframe after merge\n",
    "        merge: Dataframe\n",
    "            A new datframe after merging answers with questions\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        # merge tag_questions with tags name\n",
    "        # then group all tags for each question into single rows\n",
    "        tag_question = self._merge_data(\n",
    "            left_data=tag_questions,\n",
    "            left_key='tag_questions_tag_id',\n",
    "            right_data=tags,\n",
    "            right_key='tags_tag_id',\n",
    "            how='inner')\n",
    "        tag_question = self._group_tags(\n",
    "            data=tag_question,\n",
    "            group_by='tag_questions_question_id',\n",
    "            tag_column='tags_tag_name')\n",
    "        \n",
    "        tag_question = tag_question.rename(\n",
    "            columns={'tags_tag_name': 'questions_tag_name'})\n",
    "        \n",
    "        # merge tag_users with tags name\n",
    "        # then group all tags for each user into single rows \n",
    "        # after that rename the tag column name\n",
    "        tags_pro = self._merge_data(\n",
    "            left_data=tag_users,\n",
    "            left_key='tag_users_tag_id',\n",
    "            right_data=tags,\n",
    "            right_key='tags_tag_id',\n",
    "            how='inner')\n",
    "        tags_pro = self._group_tags(\n",
    "            data=tags_pro,\n",
    "            group_by='tag_users_user_id',\n",
    "            tag_column='tags_tag_name')\n",
    "        tags_pro = tags_pro.rename(\n",
    "            columns={'tags_tag_name': 'professionals_tag_name'})\n",
    "        \n",
    "        # merge professionals and questions tags with main merge_dataset \n",
    "        questions = self._merge_data(\n",
    "            left_data=questions,\n",
    "            left_key='questions_id',\n",
    "            right_data=tag_question,\n",
    "            right_key='tag_questions_question_id',\n",
    "            how='left')\n",
    "        professionals = self._merge_data(\n",
    "            left_data=professionals,\n",
    "            left_key='professionals_id',\n",
    "            right_data=tags_pro,\n",
    "            right_key='tag_users_user_id',\n",
    "            how='left')\n",
    "        \n",
    "        # merge questions with scores \n",
    "        questions = self._merge_data(\n",
    "            left_data=questions,\n",
    "            left_key='questions_id',\n",
    "            right_data=questions_score,\n",
    "            right_key='id',\n",
    "            how='left')\n",
    "        \n",
    "        # merge questions with students\n",
    "        questions = self._merge_data(\n",
    "            left_data=questions,\n",
    "            left_key='questions_author_id',\n",
    "            right_data=students,\n",
    "            right_key='students_id',\n",
    "            how='left')\n",
    "        \n",
    "        # merge answers with questions\n",
    "        # then merge professionals and questions score with that\n",
    "        merge = self._merge_data(\n",
    "            left_data=answers,\n",
    "            left_key='answers_question_id',\n",
    "            right_data=questions,\n",
    "            right_key='questions_id',\n",
    "            how='inner')\n",
    "        \n",
    "        merge = self._merge_data(\n",
    "            left_data=merge,\n",
    "            left_key='answers_author_id',\n",
    "            right_data=professionals,\n",
    "            right_key='professionals_id',\n",
    "            how='inner')\n",
    "        \n",
    "        return questions, professionals, merge\n",
    "  \n",
    "    def _drop_duplicates_tags(self, data, col_name):\n",
    "        # drop duplicates tags from each row\n",
    "        return (\n",
    "            data[col_name].str.split(\n",
    "                ',').apply(set).str.join(','))\n",
    "\n",
    "\n",
    "    def _merge_pro_pre_ans_tags(self, professionals, merge):\n",
    "        ########################\n",
    "        # Merge professionals previous answered\n",
    "        # questions tags into professionals tags\n",
    "        ########################\n",
    "        \n",
    "        # select professionals answered questions tags\n",
    "        # and stored as a dataframe\n",
    "        professionals_prev_ans_tags = (\n",
    "            merge[['professionals_id', 'questions_tag_name']])\n",
    "        # drop null values from that\n",
    "        professionals_prev_ans_tags = professionals_prev_ans_tags.dropna()\n",
    "        \n",
    "        # because professsionals answers multiple questions,\n",
    "        # we group all of tags of each user into single row\n",
    "        professionals_prev_ans_tags = self._group_tags(\n",
    "            data=professionals_prev_ans_tags,\n",
    "            group_by='professionals_id',\n",
    "            tag_column='questions_tag_name')\n",
    "        \n",
    "        # drop duplicates tags from each professionals rows\n",
    "        professionals_prev_ans_tags['questions_tag_name'] = \\\n",
    "        self._drop_duplicates_tags(\n",
    "            professionals_prev_ans_tags, 'questions_tag_name')\n",
    "        \n",
    "        # finally merge the dataframe with professionals dataframe\n",
    "        professionals = self._merge_data(\n",
    "            left_data=professionals,\n",
    "            left_key='professionals_id',\n",
    "            right_data=professionals_prev_ans_tags,\n",
    "            right_key='professionals_id',\n",
    "            how='left')\n",
    "        \n",
    "        # join professionals tags and their answered tags \n",
    "        # we replace nan values with \"\"\n",
    "        professionals['professional_all_tags'] = (\n",
    "            professionals[['professionals_tag_name',\n",
    "                           'questions_tag_name']].apply(\n",
    "                lambda x: ','.join(x.dropna()),\n",
    "                axis=1))\n",
    "        return professionals\n",
    "\n",
    "    def prepare(\n",
    "        self,\n",
    "        professionals,students,\n",
    "        questions,answers,\n",
    "        tags,tag_questions,tag_users, questions_score):\n",
    "        \n",
    "        \"\"\"\n",
    "        This function clean and process \n",
    "        CareerVillage Data sets. \n",
    "        \"\"\"\n",
    "        \n",
    "        # assign unique integer id\n",
    "        professionals = self._assign_unique_id(\n",
    "            professionals, 'professionals_id_num')\n",
    "        students = self._assign_unique_id(\n",
    "            students, 'students_id_num')\n",
    "        questions = self._assign_unique_id(\n",
    "            questions, 'questions_id_num')\n",
    "        answers = self._assign_unique_id(\n",
    "            answers, 'answers_id_num')\n",
    "        \n",
    "        # just dropna from tags \n",
    "        tags = tags.dropna()\n",
    "        tags['tags_tag_name'] = tags['tags_tag_name'].str.replace(\n",
    "            '#', '')\n",
    "        \n",
    "        \n",
    "        # merge necessary datasets\n",
    "        df_questions, df_professionals, df_merge = self._merge_cv_datasets(\n",
    "            professionals,students,\n",
    "            questions,answers,\n",
    "            tags,tag_questions,tag_users,\n",
    "            questions_score)\n",
    "        \n",
    "        #######################\n",
    "        # Generate some features for calculates weights\n",
    "        # that will use with interaction matrix\n",
    "        #######################\n",
    "        df_merge['num_ans_per_ques'] = df_merge.groupby(\n",
    "            ['questions_id'])['answers_id'].transform('count')\n",
    "        \n",
    "        # merge pro previoius answered question tags with pro tags \n",
    "        df_professionals = self._merge_pro_pre_ans_tags(\n",
    "            df_professionals, df_merge)\n",
    "        \n",
    "        # some more pre-processing \n",
    "        # handling null values \n",
    "        df_questions['score'] = df_questions['score'].fillna(0)\n",
    "        df_questions['score'] = df_questions['score'].astype(int)\n",
    "        df_questions['questions_tag_name'] = \\\n",
    "        df_questions['questions_tag_name'].fillna('No Tag')\n",
    "        \n",
    "        # remove duplicates tags from each questions \n",
    "        df_questions['questions_tag_name'] = \\\n",
    "        df_questions['questions_tag_name'].str.split(\n",
    "            ',').apply(set).str.join(',')\n",
    "\n",
    "        # fill nan with 'No Tag' if any \n",
    "        df_professionals['professional_all_tags'] = \\\n",
    "        df_professionals['professional_all_tags'].fillna(\n",
    "            'No Tag')\n",
    "        # replace \"\" with \"No Tag\", because previously we replace nan with \"\"\n",
    "        df_professionals['professional_all_tags'] = \\\n",
    "        df_professionals['professional_all_tags'].replace(\n",
    "            '', 'No Tag')\n",
    "        \n",
    "        df_professionals['professionals_location'] = \\\n",
    "        df_professionals['professionals_location'].fillna(\n",
    "            'No Location')\n",
    "        \n",
    "        df_professionals['professionals_industry'] = \\\n",
    "        df_professionals['professionals_industry'].fillna(\n",
    "            'No Industry')\n",
    "\n",
    "        # remove duplicates tags from each professionals\n",
    "        df_professionals['professional_all_tags'] = \\\n",
    "        df_professionals['professional_all_tags'].str.split(\n",
    "            ',').apply(set).str.join(',')\n",
    "\n",
    "        # remove some null values from df_merge\n",
    "        df_merge['num_ans_per_ques']  = \\\n",
    "        df_merge['num_ans_per_ques'].fillna(0)\n",
    "        \n",
    "        return df_questions, df_professionals, df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightFMDataPrep:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def create_features(self, dataframe, features_name, id_col_name):\n",
    "        \"\"\"\n",
    "        Generate features that will be ready for feeding into lightfm\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataframe: Dataframe\n",
    "            Pandas Dataframe which contains features\n",
    "        features_name : List\n",
    "            List of feature columns name avaiable in dataframe\n",
    "        id_col_name: String\n",
    "            Column name which contains id of the question or\n",
    "            answer that the features will map to.\n",
    "            There are two possible values for this variable.\n",
    "            1. questions_id_num\n",
    "            2. professionals_id_num\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Pandas Series\n",
    "            A pandas series containing process features\n",
    "            that are ready for feed into lightfm.\n",
    "            The format of each value\n",
    "            will be (user_id, ['feature_1', 'feature_2', 'feature_3'])\n",
    "            Ex. -> (1, ['military', 'army', '5'])\n",
    "        \"\"\"\n",
    "\n",
    "        features = dataframe[features_name].apply(\n",
    "            lambda x: ','.join(x.map(str)), axis=1)\n",
    "        features = features.str.split(',')\n",
    "        features = list(zip(dataframe[id_col_name], features))\n",
    "        return features\n",
    "\n",
    "\n",
    "\n",
    "    def generate_feature_list(self, dataframe, features_name):\n",
    "        \"\"\"\n",
    "        Generate features list for mapping \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataframe: Dataframe\n",
    "            Pandas Dataframe for Users or Q&A. \n",
    "        features_name : List\n",
    "            List of feature columns name avaiable in dataframe. \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        List of all features for mapping \n",
    "        \"\"\"\n",
    "        features = dataframe[features_name].apply(\n",
    "            lambda x: ','.join(x.map(str)), axis=1)\n",
    "        features = features.str.split(',')\n",
    "        features = features.apply(pd.Series).stack().reset_index(drop=True)\n",
    "        return features\n",
    "    \n",
    "    def create_data(self, questions, professionals, merge):\n",
    "        question_feature_list = self.generate_feature_list(\n",
    "            questions,\n",
    "            ['questions_tag_name'])\n",
    "\n",
    "        professional_feature_list = self.generate_feature_list(\n",
    "            professionals,\n",
    "            ['professional_all_tags'])\n",
    "        \n",
    "        merge['total_weights'] = 1 / (\n",
    "            merge['num_ans_per_ques'])\n",
    "        \n",
    "        # creating features for feeding into lightfm \n",
    "        questions['question_features'] = self.create_features(\n",
    "            questions, ['questions_tag_name'], \n",
    "            'questions_id_num')\n",
    "\n",
    "        professionals['professional_features'] = self.create_features(\n",
    "            professionals,\n",
    "            ['professional_all_tags'],\n",
    "            'professionals_id_num')\n",
    "        \n",
    "        return question_feature_list,\\\n",
    "    professional_feature_list,merge,questions,professionals\n",
    "        \n",
    "    def fit(self, questions, professionals, merge):\n",
    "        ########################\n",
    "        # Dataset building for lightfm\n",
    "        ########################\n",
    "        question_feature_list, \\\n",
    "        professional_feature_list,\\\n",
    "        merge,questions,professionals = \\\n",
    "        self.create_data(questions, professionals, merge)\n",
    "        \n",
    "        \n",
    "        # define our dataset variable\n",
    "        # then we feed unique professionals and questions ids\n",
    "        # and item and professional feature list\n",
    "        # this will create lightfm internel mapping\n",
    "        dataset = Dataset()\n",
    "        dataset.fit(\n",
    "            set(professionals['professionals_id_num']), \n",
    "            set(questions['questions_id_num']),\n",
    "            item_features=question_feature_list, \n",
    "            user_features=professional_feature_list)\n",
    "\n",
    "\n",
    "        # now we are building interactions\n",
    "        # matrix between professionals and quesitons\n",
    "        # we are passing professional and questions id as a tuple\n",
    "        # e.g -> pd.Series((pro_id, question_id), (pro_id, questin_id))\n",
    "        # then we use lightfm build in method for building interactions matrix\n",
    "        merge['author_question_id_tuple'] = list(zip(\n",
    "            merge.professionals_id_num,\n",
    "            merge.questions_id_num,\n",
    "            merge.total_weights))\n",
    "\n",
    "        interactions, weights = dataset.build_interactions(\n",
    "            merge['author_question_id_tuple'])\n",
    "\n",
    "\n",
    "\n",
    "        # now we are building our questions and\n",
    "        # professionals features\n",
    "        # in a way that lightfm understand.\n",
    "        # we are using lightfm build in method for building\n",
    "        # questions and professionals features \n",
    "        questions_features = dataset.build_item_features(\n",
    "            questions['question_features'])\n",
    "\n",
    "        professional_features = dataset.build_user_features(\n",
    "            professionals['professional_features'])\n",
    "        \n",
    "        return interactions, weights,questions_features,professional_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainLightFM:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def train_test_split(self, interactions, weights):\n",
    "        train_interactions, test_interactions = \\\n",
    "        cross_validation.random_train_test_split(\n",
    "            interactions, \n",
    "            random_state=np.random.RandomState(2019))\n",
    "        \n",
    "        train_weights, test_weights = \\\n",
    "        cross_validation.random_train_test_split(\n",
    "            weights, \n",
    "            random_state=np.random.RandomState(2019))\n",
    "        return train_interactions,\\\n",
    "    test_interactions, train_weights, test_weights\n",
    "    \n",
    "    def fit(self, interactions, weights,\n",
    "            questions_features, professional_features,\n",
    "            cross_validation=False,no_components=150,\n",
    "            learning_rate=0.05,\n",
    "            loss='warp',\n",
    "            random_state=2019,\n",
    "            verbose=True,\n",
    "            num_threads=4, epochs=5):\n",
    "        ################################\n",
    "        # Model building part\n",
    "        ################################\n",
    "\n",
    "        # define lightfm model by specifying hyper-parametre\n",
    "        # then fit the model with ineteractions matrix,\n",
    "        # item and user features\n",
    "        \n",
    "        model = LightFM(\n",
    "            no_components,\n",
    "            learning_rate,\n",
    "            loss=loss,\n",
    "            random_state=random_state)\n",
    "        model.fit(\n",
    "            interactions,\n",
    "            item_features=questions_features,\n",
    "            user_features=professional_features, sample_weight=weights,\n",
    "            epochs=epochs, num_threads=num_threads, verbose=verbose)\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Recommendations classs: Now we are going to build a class for making recommendations. \n",
    "This will make easy for making recommendations in djono api. This recommendations class \n",
    "build with extra features. You can use this for general prediction by giving professionals ids \n",
    "and questions features. It has another features that let's choose questions from range of two dates \n",
    "and make recommendation from those questions.\n",
    "\n",
    "This is useful because those professionals that choose email frequency lavel as \"weekly\" or \"daily\", \n",
    "we can select questions from a week and then recommend those questions.\n",
    "\"\"\"\n",
    "\n",
    "class LightFMRecommendations:\n",
    "    \"\"\"\n",
    "    Make prediction given model and professional ids\n",
    "    \"\"\"\n",
    "    def __init__(self, lightfm_model,\n",
    "                 professionals_features,\n",
    "                 questions_features,\n",
    "                 questions,professionals,merge):\n",
    "        self.model = lightfm_model\n",
    "        self.professionals_features = professionals_features\n",
    "        self.questions_features = questions_features\n",
    "        self.questions = questions\n",
    "        self.professionals = professionals\n",
    "        self.merge = merge\n",
    "        \n",
    "    def previous_answered_questions(self, professionals_id):\n",
    "        previous_q_id_num = (\n",
    "            self.merge.loc[\\\n",
    "                self.merge['professionals_id_num'] == \\\n",
    "                professionals_id]['questions_id_num'])\n",
    "        \n",
    "        previous_answered_questions = self.questions.loc[\\\n",
    "            self.questions['questions_id_num'].isin(\n",
    "            previous_q_id_num)]\n",
    "        return previous_answered_questions\n",
    "        \n",
    "    \n",
    "    def _filter_question_by_pro(self, professionals_id):\n",
    "        \"\"\"Drop questions that professional already answer\"\"\"\n",
    "        previous_answered_questions = \\\n",
    "        self.previous_answered_questions(professionals_id)\n",
    "        \n",
    "        discard_qu_id = \\\n",
    "        previous_answered_questions['questions_id_num'].values.tolist()\n",
    "        \n",
    "        questions_for_prediction = \\\n",
    "        self.questions.loc[~self.questions['questions_id_num'].isin(discard_qu_id)]\n",
    "        \n",
    "        return questions_for_prediction\n",
    "    \n",
    "    def _filter_question_by_date(self, questions, start_date, end_date):\n",
    "        mask = \\\n",
    "        (questions['questions_date_added'] > start_date) & \\\n",
    "        (questions['questions_date_added'] <= end_date)\n",
    "        \n",
    "        return questions.loc[mask]\n",
    "        \n",
    "    \n",
    "    def recommend_by_pro_id_general(self,\n",
    "                                    professional_id,\n",
    "                                    num_prediction=8):\n",
    "        questions_for_prediction = self._filter_question_by_pro(professional_id)\n",
    "        score = self.model.predict(\n",
    "            professional_id,\n",
    "            questions_for_prediction['questions_id_num'].values.tolist(), \n",
    "            item_features=self.questions_features,\n",
    "            user_features=self.professionals_features)\n",
    "        \n",
    "        questions_for_prediction['recommendation_score'] = score\n",
    "        questions_for_prediction = questions_for_prediction.sort_values(\n",
    "            by='recommendation_score', ascending=False)[:num_prediction]\n",
    "        return questions_for_prediction\n",
    "    \n",
    "    def recommend_by_pro_id_frequency_date_range(self,\n",
    "                                                 professional_id,\n",
    "                                                 start_date,\n",
    "                                                 end_date,\n",
    "                                                 num_prediction=8):\n",
    "        questions_for_prediction = \\\n",
    "        self._filter_question_by_pro(professional_id)\n",
    "        \n",
    "        start_date = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "        end_date = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "        \n",
    "        questions_for_prediction = self._filter_question_by_date(\n",
    "            questions_for_prediction, start_date, end_date)\n",
    "        \n",
    "        score = self.model.predict(\n",
    "            professional_id,\n",
    "            questions_for_prediction['questions_id_num'].values.tolist(), \n",
    "            item_features=self.questions_features,\n",
    "            user_features=self.professionals_features)\n",
    "        \n",
    "        questions_for_prediction['recommendation_score'] = score\n",
    "        questions_for_prediction = questions_for_prediction.sort_values(\n",
    "            by='recommendation_score', ascending=False)[:num_prediction]\n",
    "        return questions_for_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n"
     ]
    }
   ],
   "source": [
    "# instiate all class instance\n",
    "cv_data_prep = CareerVillageDataPreparation()\n",
    "light_fm_data_prep = LightFMDataPrep()\n",
    "train_lightfm = TrainLightFM()\n",
    "\n",
    "# process raw data\n",
    "df_questions_p, df_professionals_p, df_merge_p = \\\n",
    "cv_data_prep.prepare(\n",
    "    df_professionals,df_students,\n",
    "    df_questions,df_answers,\n",
    "    df_tags,df_tag_questions,df_tag_users,\n",
    "    df_question_scores)\n",
    "\n",
    "\n",
    "# prepare data for lightfm \n",
    "interactions, weights, \\\n",
    "questions_features, professional_features = \\\n",
    "light_fm_data_prep.fit(\n",
    "    df_questions_p, df_professionals_p, df_merge_p)\n",
    "\n",
    "\n",
    "# finally build and trian our model\n",
    "model = train_lightfm.fit(interactions,\n",
    "                          weights,\n",
    "                          questions_features,\n",
    "                          professional_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation for professional: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions_id</th>\n",
       "      <th>questions_author_id</th>\n",
       "      <th>questions_date_added</th>\n",
       "      <th>questions_title</th>\n",
       "      <th>questions_body</th>\n",
       "      <th>questions_id_num</th>\n",
       "      <th>tag_questions_question_id</th>\n",
       "      <th>questions_tag_name</th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>students_id</th>\n",
       "      <th>students_location</th>\n",
       "      <th>students_date_joined</th>\n",
       "      <th>students_id_num</th>\n",
       "      <th>question_features</th>\n",
       "      <th>recommendation_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2423</td>\n",
       "      <td>9515b833b2ac4092a8b1a8cdb380781f</td>\n",
       "      <td>941ae126a59745fa9b4556293b38c1fb</td>\n",
       "      <td>2019-01-08 20:47:44+00:00</td>\n",
       "      <td>How long does it take to become a Detective?</td>\n",
       "      <td>#law #criminal-justice #lawyer #police #law-en...</td>\n",
       "      <td>2423</td>\n",
       "      <td>9515b833b2ac4092a8b1a8cdb380781f</td>\n",
       "      <td>law,criminal-justice,police,law-enforcement,la...</td>\n",
       "      <td>9515b833b2ac4092a8b1a8cdb380781f</td>\n",
       "      <td>2</td>\n",
       "      <td>941ae126a59745fa9b4556293b38c1fb</td>\n",
       "      <td>Oakland, California</td>\n",
       "      <td>2019-01-08 20:35:58+00:00</td>\n",
       "      <td>30755.0</td>\n",
       "      <td>(2423, [law, criminal-justice, police, law-enf...</td>\n",
       "      <td>-2.352616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17184</td>\n",
       "      <td>570ca25a625d461abffac230ea110db5</td>\n",
       "      <td>941ae126a59745fa9b4556293b38c1fb</td>\n",
       "      <td>2019-01-10 01:48:47+00:00</td>\n",
       "      <td>What types of Detectives are there?</td>\n",
       "      <td>#law #criminal-justice #lawyer #law-enforcemen...</td>\n",
       "      <td>17184</td>\n",
       "      <td>570ca25a625d461abffac230ea110db5</td>\n",
       "      <td>law,criminal-justice,police,law-enforcement,la...</td>\n",
       "      <td>570ca25a625d461abffac230ea110db5</td>\n",
       "      <td>2</td>\n",
       "      <td>941ae126a59745fa9b4556293b38c1fb</td>\n",
       "      <td>Oakland, California</td>\n",
       "      <td>2019-01-08 20:35:58+00:00</td>\n",
       "      <td>30755.0</td>\n",
       "      <td>(17184, [law, criminal-justice, police, law-en...</td>\n",
       "      <td>-2.392477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9778</td>\n",
       "      <td>776e22d9eb1045eb8a9771eb015e8ddf</td>\n",
       "      <td>d7601a6cc1d04e61aaa16c95cbd0b128</td>\n",
       "      <td>2018-10-03 14:04:13+00:00</td>\n",
       "      <td>I want to be a police officer or a police disp...</td>\n",
       "      <td>#police-officer #law #law-enforcement #crimina...</td>\n",
       "      <td>9778</td>\n",
       "      <td>776e22d9eb1045eb8a9771eb015e8ddf</td>\n",
       "      <td>law,criminal-justice,police,law-enforcement,po...</td>\n",
       "      <td>776e22d9eb1045eb8a9771eb015e8ddf</td>\n",
       "      <td>2</td>\n",
       "      <td>d7601a6cc1d04e61aaa16c95cbd0b128</td>\n",
       "      <td>Olney, Illinois</td>\n",
       "      <td>2018-10-03 14:01:25+00:00</td>\n",
       "      <td>29951.0</td>\n",
       "      <td>(9778, [law, criminal-justice, police, law-enf...</td>\n",
       "      <td>-2.759542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18872</td>\n",
       "      <td>c3e6e57cb27b4134be9b8608a711e2fc</td>\n",
       "      <td>43f813594dd44e16843ecae4e2362ead</td>\n",
       "      <td>2015-03-23 21:17:34+00:00</td>\n",
       "      <td>What majors would fit a law enforcement career?</td>\n",
       "      <td>Im asking this question because I've heard tha...</td>\n",
       "      <td>18872</td>\n",
       "      <td>c3e6e57cb27b4134be9b8608a711e2fc</td>\n",
       "      <td>law,law-enforcement,police</td>\n",
       "      <td>c3e6e57cb27b4134be9b8608a711e2fc</td>\n",
       "      <td>4</td>\n",
       "      <td>43f813594dd44e16843ecae4e2362ead</td>\n",
       "      <td>Los Angeles, California</td>\n",
       "      <td>2015-03-23 21:09:01+00:00</td>\n",
       "      <td>3322.0</td>\n",
       "      <td>(18872, [law, law-enforcement, police])</td>\n",
       "      <td>-2.781396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20003</td>\n",
       "      <td>36a31f62e40748bfa9feb069082086d7</td>\n",
       "      <td>59e78bc12f624fc9bc8ee1c8878f34b2</td>\n",
       "      <td>2017-10-24 21:04:39+00:00</td>\n",
       "      <td>how many criminal psychologist jobs are our th...</td>\n",
       "      <td>I want to be one. #criminal-justice #psycholog...</td>\n",
       "      <td>20003</td>\n",
       "      <td>36a31f62e40748bfa9feb069082086d7</td>\n",
       "      <td>criminal-justice,psychology,law-enforcement</td>\n",
       "      <td>36a31f62e40748bfa9feb069082086d7</td>\n",
       "      <td>3</td>\n",
       "      <td>59e78bc12f624fc9bc8ee1c8878f34b2</td>\n",
       "      <td>Fontana, California</td>\n",
       "      <td>2017-10-24 20:56:11+00:00</td>\n",
       "      <td>22222.0</td>\n",
       "      <td>(20003, [criminal-justice, psychology, law-enf...</td>\n",
       "      <td>-2.793029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18947</td>\n",
       "      <td>cdd0b274ec8f4122a39989707342ccfe</td>\n",
       "      <td>8a8305d32bd144d5877842dcabdfb6d7</td>\n",
       "      <td>2016-05-05 15:39:53+00:00</td>\n",
       "      <td>Could I go straight into Law Enforcememt, when...</td>\n",
       "      <td>I am an explorer and is trying to set my caree...</td>\n",
       "      <td>18947</td>\n",
       "      <td>cdd0b274ec8f4122a39989707342ccfe</td>\n",
       "      <td>law,law-enforcement,police</td>\n",
       "      <td>cdd0b274ec8f4122a39989707342ccfe</td>\n",
       "      <td>4</td>\n",
       "      <td>8a8305d32bd144d5877842dcabdfb6d7</td>\n",
       "      <td>Laurinburg, North Carolina</td>\n",
       "      <td>2016-05-02 16:37:52+00:00</td>\n",
       "      <td>7103.0</td>\n",
       "      <td>(18947, [law, law-enforcement, police])</td>\n",
       "      <td>-2.825045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16214</td>\n",
       "      <td>ccb15b06a96a4bcfb4d5844550af25cc</td>\n",
       "      <td>8a8305d32bd144d5877842dcabdfb6d7</td>\n",
       "      <td>2016-05-04 16:32:58+00:00</td>\n",
       "      <td>Do you go to college, then B.L.E.T( Basic Law ...</td>\n",
       "      <td>I am an explorer and is trying to set my caree...</td>\n",
       "      <td>16214</td>\n",
       "      <td>ccb15b06a96a4bcfb4d5844550af25cc</td>\n",
       "      <td>law,law-enforcement,police</td>\n",
       "      <td>ccb15b06a96a4bcfb4d5844550af25cc</td>\n",
       "      <td>2</td>\n",
       "      <td>8a8305d32bd144d5877842dcabdfb6d7</td>\n",
       "      <td>Laurinburg, North Carolina</td>\n",
       "      <td>2016-05-02 16:37:52+00:00</td>\n",
       "      <td>7103.0</td>\n",
       "      <td>(16214, [law, law-enforcement, police])</td>\n",
       "      <td>-2.851564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1936</td>\n",
       "      <td>c544db1b7cda482497adcf059f36e709</td>\n",
       "      <td>f0eeb9fe04884944b5abffe2b7011b84</td>\n",
       "      <td>2017-02-08 19:27:57+00:00</td>\n",
       "      <td>What degrees do you have to have in order to g...</td>\n",
       "      <td>Law enforcement is a career I am interested in...</td>\n",
       "      <td>1936</td>\n",
       "      <td>c544db1b7cda482497adcf059f36e709</td>\n",
       "      <td>criminal-justice,law-enforcement,police</td>\n",
       "      <td>c544db1b7cda482497adcf059f36e709</td>\n",
       "      <td>4</td>\n",
       "      <td>f0eeb9fe04884944b5abffe2b7011b84</td>\n",
       "      <td>Gibson, Louisiana</td>\n",
       "      <td>2017-02-03 18:29:06+00:00</td>\n",
       "      <td>17965.0</td>\n",
       "      <td>(1936, [criminal-justice, law-enforcement, pol...</td>\n",
       "      <td>-2.853464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           questions_id               questions_author_id  \\\n",
       "2423   9515b833b2ac4092a8b1a8cdb380781f  941ae126a59745fa9b4556293b38c1fb   \n",
       "17184  570ca25a625d461abffac230ea110db5  941ae126a59745fa9b4556293b38c1fb   \n",
       "9778   776e22d9eb1045eb8a9771eb015e8ddf  d7601a6cc1d04e61aaa16c95cbd0b128   \n",
       "18872  c3e6e57cb27b4134be9b8608a711e2fc  43f813594dd44e16843ecae4e2362ead   \n",
       "20003  36a31f62e40748bfa9feb069082086d7  59e78bc12f624fc9bc8ee1c8878f34b2   \n",
       "18947  cdd0b274ec8f4122a39989707342ccfe  8a8305d32bd144d5877842dcabdfb6d7   \n",
       "16214  ccb15b06a96a4bcfb4d5844550af25cc  8a8305d32bd144d5877842dcabdfb6d7   \n",
       "1936   c544db1b7cda482497adcf059f36e709  f0eeb9fe04884944b5abffe2b7011b84   \n",
       "\n",
       "           questions_date_added  \\\n",
       "2423  2019-01-08 20:47:44+00:00   \n",
       "17184 2019-01-10 01:48:47+00:00   \n",
       "9778  2018-10-03 14:04:13+00:00   \n",
       "18872 2015-03-23 21:17:34+00:00   \n",
       "20003 2017-10-24 21:04:39+00:00   \n",
       "18947 2016-05-05 15:39:53+00:00   \n",
       "16214 2016-05-04 16:32:58+00:00   \n",
       "1936  2017-02-08 19:27:57+00:00   \n",
       "\n",
       "                                         questions_title  \\\n",
       "2423        How long does it take to become a Detective?   \n",
       "17184                What types of Detectives are there?   \n",
       "9778   I want to be a police officer or a police disp...   \n",
       "18872    What majors would fit a law enforcement career?   \n",
       "20003  how many criminal psychologist jobs are our th...   \n",
       "18947  Could I go straight into Law Enforcememt, when...   \n",
       "16214  Do you go to college, then B.L.E.T( Basic Law ...   \n",
       "1936   What degrees do you have to have in order to g...   \n",
       "\n",
       "                                          questions_body  questions_id_num  \\\n",
       "2423   #law #criminal-justice #lawyer #police #law-en...              2423   \n",
       "17184  #law #criminal-justice #lawyer #law-enforcemen...             17184   \n",
       "9778   #police-officer #law #law-enforcement #crimina...              9778   \n",
       "18872  Im asking this question because I've heard tha...             18872   \n",
       "20003  I want to be one. #criminal-justice #psycholog...             20003   \n",
       "18947  I am an explorer and is trying to set my caree...             18947   \n",
       "16214  I am an explorer and is trying to set my caree...             16214   \n",
       "1936   Law enforcement is a career I am interested in...              1936   \n",
       "\n",
       "              tag_questions_question_id  \\\n",
       "2423   9515b833b2ac4092a8b1a8cdb380781f   \n",
       "17184  570ca25a625d461abffac230ea110db5   \n",
       "9778   776e22d9eb1045eb8a9771eb015e8ddf   \n",
       "18872  c3e6e57cb27b4134be9b8608a711e2fc   \n",
       "20003  36a31f62e40748bfa9feb069082086d7   \n",
       "18947  cdd0b274ec8f4122a39989707342ccfe   \n",
       "16214  ccb15b06a96a4bcfb4d5844550af25cc   \n",
       "1936   c544db1b7cda482497adcf059f36e709   \n",
       "\n",
       "                                      questions_tag_name  \\\n",
       "2423   law,criminal-justice,police,law-enforcement,la...   \n",
       "17184  law,criminal-justice,police,law-enforcement,la...   \n",
       "9778   law,criminal-justice,police,law-enforcement,po...   \n",
       "18872                         law,law-enforcement,police   \n",
       "20003        criminal-justice,psychology,law-enforcement   \n",
       "18947                         law,law-enforcement,police   \n",
       "16214                         law,law-enforcement,police   \n",
       "1936             criminal-justice,law-enforcement,police   \n",
       "\n",
       "                                     id  score  \\\n",
       "2423   9515b833b2ac4092a8b1a8cdb380781f      2   \n",
       "17184  570ca25a625d461abffac230ea110db5      2   \n",
       "9778   776e22d9eb1045eb8a9771eb015e8ddf      2   \n",
       "18872  c3e6e57cb27b4134be9b8608a711e2fc      4   \n",
       "20003  36a31f62e40748bfa9feb069082086d7      3   \n",
       "18947  cdd0b274ec8f4122a39989707342ccfe      4   \n",
       "16214  ccb15b06a96a4bcfb4d5844550af25cc      2   \n",
       "1936   c544db1b7cda482497adcf059f36e709      4   \n",
       "\n",
       "                            students_id           students_location  \\\n",
       "2423   941ae126a59745fa9b4556293b38c1fb         Oakland, California   \n",
       "17184  941ae126a59745fa9b4556293b38c1fb         Oakland, California   \n",
       "9778   d7601a6cc1d04e61aaa16c95cbd0b128             Olney, Illinois   \n",
       "18872  43f813594dd44e16843ecae4e2362ead     Los Angeles, California   \n",
       "20003  59e78bc12f624fc9bc8ee1c8878f34b2         Fontana, California   \n",
       "18947  8a8305d32bd144d5877842dcabdfb6d7  Laurinburg, North Carolina   \n",
       "16214  8a8305d32bd144d5877842dcabdfb6d7  Laurinburg, North Carolina   \n",
       "1936   f0eeb9fe04884944b5abffe2b7011b84           Gibson, Louisiana   \n",
       "\n",
       "           students_date_joined  students_id_num  \\\n",
       "2423  2019-01-08 20:35:58+00:00          30755.0   \n",
       "17184 2019-01-08 20:35:58+00:00          30755.0   \n",
       "9778  2018-10-03 14:01:25+00:00          29951.0   \n",
       "18872 2015-03-23 21:09:01+00:00           3322.0   \n",
       "20003 2017-10-24 20:56:11+00:00          22222.0   \n",
       "18947 2016-05-02 16:37:52+00:00           7103.0   \n",
       "16214 2016-05-02 16:37:52+00:00           7103.0   \n",
       "1936  2017-02-03 18:29:06+00:00          17965.0   \n",
       "\n",
       "                                       question_features  recommendation_score  \n",
       "2423   (2423, [law, criminal-justice, police, law-enf...             -2.352616  \n",
       "17184  (17184, [law, criminal-justice, police, law-en...             -2.392477  \n",
       "9778   (9778, [law, criminal-justice, police, law-enf...             -2.759542  \n",
       "18872            (18872, [law, law-enforcement, police])             -2.781396  \n",
       "20003  (20003, [criminal-justice, psychology, law-enf...             -2.793029  \n",
       "18947            (18947, [law, law-enforcement, police])             -2.825045  \n",
       "16214            (16214, [law, law-enforcement, police])             -2.851564  \n",
       "1936   (1936, [criminal-justice, law-enforcement, pol...             -2.853464  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define our recommender class\n",
    "lightfm_recommendations = LightFMRecommendations(\n",
    "    model,\n",
    "    professional_features,questions_features,\n",
    "    df_questions_p, df_professionals_p, df_merge_p)\n",
    "\n",
    "# let's what our model predict for user id 3\n",
    "print(\"Recommendation for professional: \" + str(3))\n",
    "display(lightfm_recommendations.recommend_by_pro_id_general(3)[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for professionals (question from 2016-1-1 to 2016-12-31): 3\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot compare tz-naive and tz-aware datetime-like objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-fecd08216f14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# given questions between two dates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Recommendations for professionals (question from 2016-1-1 to 2016-12-31): \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlightfm_recommendations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecommend_by_pro_id_frequency_date_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2016-1-1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'2016-12-31'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-32075039dcce>\u001b[0m in \u001b[0;36mrecommend_by_pro_id_frequency_date_range\u001b[0;34m(self, professional_id, start_date, end_date, num_prediction)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         questions_for_prediction = self._filter_question_by_date(\n\u001b[0;32m---> 87\u001b[0;31m             questions_for_prediction, start_date, end_date)\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         score = self.model.predict(\n",
      "\u001b[0;32m<ipython-input-22-32075039dcce>\u001b[0m in \u001b[0;36m_filter_question_by_date\u001b[0;34m(self, questions, start_date, end_date)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_filter_question_by_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'questions_date_added'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'questions_date_added'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m   1177\u001b[0m                 \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m             \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch_to_index_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatetimeIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mdispatch_to_index_op\u001b[0;34m(op, left, right, index_class)\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0mleft_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleft_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shallow_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNullFrequencyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;31m# DatetimeIndex and TimedeltaIndex with freq == None raise ValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/datetimelike.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaybe_unwrap_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/arrays/datetimes.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;31m# GH#18435 strings get a pass from tzawareness compat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_tzawareness_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/arrays/datetimes.py\u001b[0m in \u001b[0;36m_assert_tzawareness_compat\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mother_tz\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             raise TypeError(\n\u001b[0;32m--> 793\u001b[0;31m                 \u001b[0;34m\"Cannot compare tz-naive and tz-aware \"\u001b[0m \u001b[0;34m\"datetime-like objects\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m             )\n\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot compare tz-naive and tz-aware datetime-like objects"
     ]
    }
   ],
   "source": [
    "# also let's see what our model predicts for professional 3\n",
    "# given questions between two dates\n",
    "print(\"Recommendations for professionals (question from 2016-1-1 to 2016-12-31): \" + str(3))\n",
    "display(lightfm_recommendations.recommend_by_pro_id_frequency_date_range(3, '2016-1-1','2016-12-31')[:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! We can see our recommendations. Also, we can see, the new recommendation class has a method for recommending questions by a frequency of date. This is very helpful for recommending questions to professionals that have set their email frequency to daily or weekly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Idea that I tried but don't implemented in this notebook:\n",
    "\n",
    "Adding location features: I tried adding location features but somehow it decreases model AUC score to 91% to 84%. That's why I don't use that features.\n",
    "Adding dates and hearts data: I also tried that but it doesn't improve AUC score.\n",
    "Correcting spelling error: I tried this method and successfully implemented it. But this is really slow. For that reason, I exluded it.\n",
    "Idea that I think is important don't implemented in this notebook:\n",
    "\n",
    "Adding professionals industry and title as a features. This will inhance our model diversity and will increase overall recommendations score.\n",
    "CareerVillage should auto correct the hashtags for students questions asking time. This will help the model to match the tags more efficiently.\n",
    "For those professionals those have choosen email frequency to immediete, we can create another same model just exchange user/item features. I mean train our model by giving questions as users and professionals as items. In this way, we can predict professionals by giving a questions. So that it helps to target daily frequency professionals.\n",
    "Finally we came to end. I want give you a big thank you for reading this notebook. I have provided a very good recommender system for CareerVillage in the notebook. If you find any mistakes or have any suggestions feel free to comment. And don't forget to upvote. Good luck!\n",
    "\n",
    "References:\n",
    "\n",
    "[1] Improving Pairwise Learning for Item Recommendation from Implicit Feedback\n",
    "\n",
    "[2] Content-based filtering\n",
    "\n",
    "[3] What Is Content-Based Filtering?\n",
    "\n",
    "[4] What Is Collaborative Filtering?\n",
    "\n",
    "[5] Collaborative filtering\n",
    "\n",
    "[6] LightFM model documentation\n",
    "\n",
    "[7] Metadata Embeddings for User and Item Cold-start Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "https://www.kaggle.com/niyamatalmass/lightfm-hybrid-recommendation-system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
