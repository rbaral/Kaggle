{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook narrates the <a href=\"https://www.kaggle.com/c/expedia-hotel-recommendations\">Kaggle Expedia hotel recommendations competition </a>. I would like to acknowledge Vik Paruchuri for providing the wonderful guide for this competition.\n",
    "\n",
    "The competition Details can be found at the above link. But I would like to summarize it for quick insight.\n",
    "\n",
    "<b> The Expedia Kaggle competition</b>\n",
    "\n",
    "The Expedia competition challenges you with predicting what hotel a user will book based on some attributes about the search the user is conducting on Expedia. Before we dive into any coding, we’ll need to put in time to understand both the problem and the data.\n",
    "\n",
    "<b> Data Fields </b>\n",
    "\n",
    "The details of the data fields is available at Kaggle site <a href=\"https://www.kaggle.com/c/expedia-hotel-recommendations/data\"> data details </a>.\n",
    "\n",
    "\n",
    "<b> Data Exploration </b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#library imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "destinations = pd.read_csv(\"destinations.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: (37670293, 24)\n",
      "test data size: (2528243, 22)\n"
     ]
    }
   ],
   "source": [
    "#lets see the size of the different data files\n",
    "print(\"train data size:\",train.shape)\n",
    "print(\"test data size:\",test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have about 37 million training set rows, and 2 million testing set rows, which will make this problem a bit challenging to work with.\n",
    "\n",
    "We can explore the first few rows of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>site_name</th>\n",
       "      <th>posa_continent</th>\n",
       "      <th>user_location_country</th>\n",
       "      <th>user_location_region</th>\n",
       "      <th>user_location_city</th>\n",
       "      <th>orig_destination_distance</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_mobile</th>\n",
       "      <th>is_package</th>\n",
       "      <th>...</th>\n",
       "      <th>srch_children_cnt</th>\n",
       "      <th>srch_rm_cnt</th>\n",
       "      <th>srch_destination_id</th>\n",
       "      <th>srch_destination_type_id</th>\n",
       "      <th>is_booking</th>\n",
       "      <th>cnt</th>\n",
       "      <th>hotel_continent</th>\n",
       "      <th>hotel_country</th>\n",
       "      <th>hotel_market</th>\n",
       "      <th>hotel_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-08-11 07:46:59</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>348</td>\n",
       "      <td>48862</td>\n",
       "      <td>2234.2641</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>628</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-08-11 08:22:12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>348</td>\n",
       "      <td>48862</td>\n",
       "      <td>2234.2641</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>628</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-08-11 08:24:33</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>348</td>\n",
       "      <td>48862</td>\n",
       "      <td>2234.2641</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>628</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-08-09 18:05:16</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>442</td>\n",
       "      <td>35390</td>\n",
       "      <td>913.1932</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14984</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>1457</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-08-09 18:08:18</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>442</td>\n",
       "      <td>35390</td>\n",
       "      <td>913.6259</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14984</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>1457</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date_time  site_name  posa_continent  user_location_country  \\\n",
       "0  2014-08-11 07:46:59          2               3                     66   \n",
       "1  2014-08-11 08:22:12          2               3                     66   \n",
       "2  2014-08-11 08:24:33          2               3                     66   \n",
       "3  2014-08-09 18:05:16          2               3                     66   \n",
       "4  2014-08-09 18:08:18          2               3                     66   \n",
       "\n",
       "   user_location_region  user_location_city  orig_destination_distance  \\\n",
       "0                   348               48862                  2234.2641   \n",
       "1                   348               48862                  2234.2641   \n",
       "2                   348               48862                  2234.2641   \n",
       "3                   442               35390                   913.1932   \n",
       "4                   442               35390                   913.6259   \n",
       "\n",
       "   user_id  is_mobile  is_package      ...        srch_children_cnt  \\\n",
       "0       12          0           1      ...                        0   \n",
       "1       12          0           1      ...                        0   \n",
       "2       12          0           0      ...                        0   \n",
       "3       93          0           0      ...                        0   \n",
       "4       93          0           0      ...                        0   \n",
       "\n",
       "  srch_rm_cnt srch_destination_id  srch_destination_type_id  is_booking  cnt  \\\n",
       "0           1                8250                         1           0    3   \n",
       "1           1                8250                         1           1    1   \n",
       "2           1                8250                         1           0    1   \n",
       "3           1               14984                         1           0    1   \n",
       "4           1               14984                         1           0    1   \n",
       "\n",
       "   hotel_continent  hotel_country  hotel_market  hotel_cluster  \n",
       "0                2             50           628              1  \n",
       "1                2             50           628              1  \n",
       "2                2             50           628              1  \n",
       "3                2             50          1457             80  \n",
       "4                2             50          1457             21  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head() #displays first 5 rows by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few things that immediately stick out:\n",
    "\n",
    "<ul>\n",
    "<li> date_time could be useful in our predictions, so we’ll need to convert it.\n",
    "<li> Most of the columns are integers or floats, so we can’t do a lot of feature engineering. For example, user_location_country isn’t the name of a country, it’s an integer. This makes it harder to create new features, because we don’t know exactly which each value means.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date_time</th>\n",
       "      <th>site_name</th>\n",
       "      <th>posa_continent</th>\n",
       "      <th>user_location_country</th>\n",
       "      <th>user_location_region</th>\n",
       "      <th>user_location_city</th>\n",
       "      <th>orig_destination_distance</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_mobile</th>\n",
       "      <th>...</th>\n",
       "      <th>srch_ci</th>\n",
       "      <th>srch_co</th>\n",
       "      <th>srch_adults_cnt</th>\n",
       "      <th>srch_children_cnt</th>\n",
       "      <th>srch_rm_cnt</th>\n",
       "      <th>srch_destination_id</th>\n",
       "      <th>srch_destination_type_id</th>\n",
       "      <th>hotel_continent</th>\n",
       "      <th>hotel_country</th>\n",
       "      <th>hotel_market</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-09-03 17:09:54</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>174</td>\n",
       "      <td>37449</td>\n",
       "      <td>5539.0567</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-05-19</td>\n",
       "      <td>2016-05-23</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12243</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>204</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-09-24 17:38:35</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>174</td>\n",
       "      <td>37449</td>\n",
       "      <td>5873.2923</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>2016-05-15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14474</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>204</td>\n",
       "      <td>1540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-07 15:53:02</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>142</td>\n",
       "      <td>17440</td>\n",
       "      <td>3975.9776</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-07-26</td>\n",
       "      <td>2015-07-27</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11353</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-09-14 14:49:10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>258</td>\n",
       "      <td>34156</td>\n",
       "      <td>1508.5975</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-09-14</td>\n",
       "      <td>2015-09-16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8250</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-07-17 09:32:04</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>467</td>\n",
       "      <td>36345</td>\n",
       "      <td>66.7913</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-07-22</td>\n",
       "      <td>2015-07-23</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11812</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id            date_time  site_name  posa_continent  user_location_country  \\\n",
       "0   0  2015-09-03 17:09:54          2               3                     66   \n",
       "1   1  2015-09-24 17:38:35          2               3                     66   \n",
       "2   2  2015-06-07 15:53:02          2               3                     66   \n",
       "3   3  2015-09-14 14:49:10          2               3                     66   \n",
       "4   4  2015-07-17 09:32:04          2               3                     66   \n",
       "\n",
       "   user_location_region  user_location_city  orig_destination_distance  \\\n",
       "0                   174               37449                  5539.0567   \n",
       "1                   174               37449                  5873.2923   \n",
       "2                   142               17440                  3975.9776   \n",
       "3                   258               34156                  1508.5975   \n",
       "4                   467               36345                    66.7913   \n",
       "\n",
       "   user_id  is_mobile      ...          srch_ci     srch_co srch_adults_cnt  \\\n",
       "0        1          1      ...       2016-05-19  2016-05-23               2   \n",
       "1        1          1      ...       2016-05-12  2016-05-15               2   \n",
       "2       20          0      ...       2015-07-26  2015-07-27               4   \n",
       "3       28          0      ...       2015-09-14  2015-09-16               2   \n",
       "4       50          0      ...       2015-07-22  2015-07-23               2   \n",
       "\n",
       "  srch_children_cnt  srch_rm_cnt  srch_destination_id  \\\n",
       "0                 0            1                12243   \n",
       "1                 0            1                14474   \n",
       "2                 0            1                11353   \n",
       "3                 0            1                 8250   \n",
       "4                 0            1                11812   \n",
       "\n",
       "   srch_destination_type_id  hotel_continent  hotel_country  hotel_market  \n",
       "0                         6                6            204            27  \n",
       "1                         7                6            204          1540  \n",
       "2                         1                2             50           699  \n",
       "3                         1                2             50           628  \n",
       "4                         1                2             50           538  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few things we can take away from looking at test.csv:\n",
    "\n",
    "<ul>\n",
    "<li> It looks like all the dates in test.csv are later than the dates in train.csv, and the <a href=\"https://www.kaggle.com/c/expedia-hotel-recommendations/data\">data page</a> confirms this. The testing set contains dates from 2015, and the training set contains dates from 2013 and 2014.\n",
    "<li> It looks like the user ids in test.csv are a subset of the user ids in train.csv, given the overlapping integer ranges. We can confirm this later on.\n",
    "<li> The is_booking column always looks to be 1 in test.csv. The <a href=\"https://www.kaggle.com/c/expedia-hotel-recommendations/data\">data page</a> confirms this.\n",
    "</ul>\n",
    "\n",
    "\n",
    "<b> What to predict </b>\n",
    "\n",
    "\n",
    "We’ll be predicting which hotel_cluster a user will book after a given search. According to the description, there are 100 clusters in total.\n",
    "\n",
    "\n",
    "<b> How we’ll be scored </b>\n",
    "\n",
    "The evaluation page says that we’ll be scored using Mean Average Precision @ 5, which means that we’ll need to make 5 cluster predictions for each row, and will be scored on whether or not the correct prediction appears in our list. If the correct prediction comes earlier in the list, we get more points.\n",
    "\n",
    "For example, if the “correct” cluster is 3, and we predict 4, 43, 60, 3, 20, our score will be lower than if we predict 3, 4, 43, 60, 20. We should put predictions we’re more certain about earlier in our list of predictions.\n",
    "\n",
    "\n",
    "<b> Exploring Hotel Clusters </b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91    1043720\n",
       "41     772743\n",
       "48     754033\n",
       "64     704734\n",
       "65     670960\n",
       "5      620194\n",
       "98     589178\n",
       "59     570291\n",
       "42     551605\n",
       "21     550092\n",
       "70     545572\n",
       "18     545284\n",
       "83     534132\n",
       "46     534038\n",
       "25     530591\n",
       "62     518809\n",
       "95     509266\n",
       "28     507016\n",
       "68     503797\n",
       "82     503755\n",
       "37     496061\n",
       "50     489892\n",
       "30     489287\n",
       "9      488328\n",
       "58     483253\n",
       "97     479446\n",
       "16     477868\n",
       "72     457463\n",
       "1      452694\n",
       "99     444887\n",
       "       ...   \n",
       "19     282893\n",
       "84     278264\n",
       "66     273505\n",
       "38     269246\n",
       "87     260398\n",
       "23     259233\n",
       "12     259022\n",
       "31     257587\n",
       "67     255946\n",
       "43     253578\n",
       "7      252447\n",
       "54     250745\n",
       "92     244343\n",
       "89     243560\n",
       "45     241408\n",
       "49     240124\n",
       "3      225250\n",
       "80     220218\n",
       "60     217919\n",
       "71     216054\n",
       "93     214293\n",
       "86     209054\n",
       "14     192299\n",
       "75     165226\n",
       "24     164127\n",
       "35     139122\n",
       "53     134812\n",
       "88     107784\n",
       "27     105040\n",
       "74      48355\n",
       "Name: hotel_cluster, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"hotel_cluster\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above is truncated, but it shows that the number of hotels in each cluster is fairly evenly distributed. There doesn’t appear to be any relationship between cluster number and the number of items.\n",
    "\n",
    "<b>Exploring train and test user ids</b>\n",
    "\n",
    "\n",
    "Finally, we’ll confirm our hypothesis that all the test user ids are found in the train DataFrame. We can do this by finding the unique values for user_id in test, and seeing if they all exist in train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the intersection of train and test user ids\n",
    "test_ids = set(test[\"user_id\"].unique())\n",
    "train_ids = set(train.user_id.unique())\n",
    "intersection_count = len(test_ids & train_ids)\n",
    "intersection_count == len(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1181577 1181577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#another way to do this using numpy array\n",
    "a = np.array(list(test_ids)) # donot know why in jupyter I need to cast the set to list before converting to array, in python console a set can be directly converted to array\n",
    "b = np.array(list(train_ids))\n",
    "common_users = np.intersect1d(a, b)\n",
    "print(len(common_users), len(test_ids))\n",
    "len(common_users) == len(test_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like our hypothesis is correct, which will make working with this data much easier!\n",
    "\n",
    "<b> Downsampling our Kaggle data </b>\n",
    "\n",
    "\n",
    "The entire train.csv dataset contains 37 million rows, which makes it hard to experiment with different techniques. Ideally, we want a small enough dataset that lets us quickly iterate through different approaches but is still representative of the whole training data.\n",
    "\n",
    "We can do this by first randomly sampling rows from our data, then selecting new training and testing datasets from train.csv. By selecting both sets from train.csv, we’ll have the true hotel_cluster label for every row, and we’ll be able to calculate our accuracy as we test techniques\n",
    "\n",
    "<b> Add in times and dates</b>\n",
    "\n",
    "The first step is to add month and year fields to train. Because the train and test data is differentiated by date, we’ll need to add date fields to allow us to segment our data into two sets the same way. If we add year and month fields, we can split our data into training and testing sets using them.\n",
    "\n",
    "The code below will:\n",
    "<ul>\n",
    "<li> Convert the date_time column in train from an object to a datetime value. This makes it easier to work with as a date.\n",
    "<li> Extract the year and month from from date_time, and assign them to their own columns.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[\"date_time\"] = pd.to_datetime(train[\"date_time\"])\n",
    "train[\"year\"] = train[\"date_time\"].dt.year\n",
    "train[\"month\"] = train[\"date_time\"].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Pick 10000 users</b>\n",
    "\n",
    "Because the user ids in test are a subset of the user ids in train, we’ll need to do our random sampling in a way that preserves the full data of each user. We can accomplish this by selecting a certain number of users randomly, then only picking rows from train where user_id is in our random sample of user ids.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "unique_user_ids = train[\"user_id\"].unique()\n",
    "sel_user_ids = random.sample(set(unique_user_ids),10000)\n",
    "sel_train = train[train.user_id.isin(sel_user_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Pick new training and testing sets </b>\n",
    "\n",
    "We’ll now need to pick new training and testing sets from sel_train. We’ll call these sets t1 and t2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = sel_train[((sel_train.year == 2013) | ((sel_train.year == 2014) & (sel_train.month < 8)))]\n",
    "t2 = sel_train[((sel_train.year == 2014) & (sel_train.month >= 8))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In the original train and test DataFrames, test contained data from 2015, and train contained data from 2013 and 2014. We split this data so that anything after July 2014 is in t2, and anything before is in t1. This gives us smaller training and testing sets with similar characteristics to train and test.\n",
    "\n",
    "<b> Remove click events</b>\n",
    "\n",
    "If is_booking is 0, it represents a click, and a 1 represents a booking.  test contains only booking events, so we’ll need to sample t2 to only contain bookings as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t2 = t2[t2.is_booking == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> A simple algorithm</b>\n",
    "\n",
    "\n",
    "The most simple technique we could try on this data is to find the most common clusters across the data, then use them as predictions. (Whichever cluster has many user_ids will be assumed to be the WINNER!!!)\n",
    "\n",
    "We can again use the value_counts method to help us here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lets take few of the top clusters\n",
    "most_common_clusters = list(train.hotel_cluster.value_counts().head().index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The above code will give us a list of the 5 most common clusters in train. This is because the head method returns the first 5 rows by default, and the index property will return the index of the DataFrame, which is the hotel cluster after running the value_counts method.\n",
    "\n",
    "<b>Generating predictions</b>\n",
    "\n",
    "\n",
    "We can turn most_common_clusters into a list of predictions by making the same prediction for each row.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [most_common_clusters for i in range(t2.shape[0])]\n",
    "#print(predictions[0])\n",
    "#print(len(predictions), t2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create a list with as many elements as there are rows in t2. Each element will be equal to most_common_clusters.\n",
    "\n",
    "<b> Evaluating error</b>\n",
    "\n",
    "\n",
    "In order to evaluate error, we’ll first need to figure out how to compute Mean Average Precision. Luckily, <a href=\"https://github.com/benhamner\">Ben Hamner</a> has written an implementation that can be found <a href=\"https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/average_precision.py\">here</a>. It can be installed as part of the ml_metrics package, and you can find installation instructions for how to install it here.\n",
    "\n",
    "We can compute our error metric with the mapk method in ml_metrics. Rather than installing, I am copying the actual code from the above link, to avoid installation and restart of the notebook in the middle of work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0616247700797\n"
     ]
    }
   ],
   "source": [
    "target = [[l] for l in t2[\"hotel_cluster\"]]\n",
    "#metrics.mapk(target, predictions, k=5)\n",
    "#the mapk takes list of lists as the target and predictions\n",
    "print(mapk(target, predictions, k=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our target needs to be in list of lists format for mapk to work, so we convert the hotel_cluster column of t2 into a list of lists. Then, we call the mapk method with our target, our predictions, and the number of predictions we want to evaluate (5).\n",
    "\n",
    "Our result here isn’t great, but we’ve just generated our first set of predictions, and evaluated our error! The framework we’ve built will allow us to quickly test out a variety of techniques and see how they score. We’re well on our way to building a good-performing solution for the leaderboard.\n",
    "\n",
    "<b> Finding correlations </b>\n",
    "\n",
    "\n",
    "Before we move on to creating a better algorithm, let’s see if anything correlates well with hotel_cluster. This will tell us if we should dive more into any particular columns.\n",
    "\n",
    "We can find linear correlations in the training set using the corr method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "site_name                   -0.022408\n",
       "posa_continent               0.014938\n",
       "user_location_country       -0.010477\n",
       "user_location_region         0.007453\n",
       "user_location_city           0.000831\n",
       "orig_destination_distance    0.007260\n",
       "user_id                      0.001052\n",
       "is_mobile                    0.008412\n",
       "is_package                   0.038733\n",
       "channel                      0.000707\n",
       "srch_adults_cnt              0.012309\n",
       "srch_children_cnt            0.016261\n",
       "srch_rm_cnt                 -0.005954\n",
       "srch_destination_id         -0.011712\n",
       "srch_destination_type_id    -0.032850\n",
       "is_booking                  -0.021548\n",
       "cnt                          0.002944\n",
       "hotel_continent             -0.013963\n",
       "hotel_country               -0.024289\n",
       "hotel_market                 0.034205\n",
       "hotel_cluster                1.000000\n",
       "year                        -0.001050\n",
       "month                       -0.000560\n",
       "Name: hotel_cluster, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.corr()[\"hotel_cluster\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that no columns correlate linearly with hotel_cluster. This makes sense, because there is no linear ordering to hotel_cluster. For example, having a higher cluster number isn’t tied to having a higher srch_destination_id.\n",
    "\n",
    "Unfortunately, this means that techniques like linear regression and logistic regression won’t work well on our data, because they rely on linear correlations between predictors and targets.\n",
    "\n",
    "\n",
    "\n",
    "<b> Creating better predictions for our Kaggle entry</b>\n",
    "\n",
    "This data for this competition is quite difficult to make predictions on using machine learning for a few reasons:\n",
    "\n",
    "<ul>\n",
    "\n",
    "<li> There are millions of rows, which increases runtime and memory usage for algorithms.\n",
    "\n",
    "<li> There are 100 different clusters, and according to the competition admins, the boundaries are fairly fuzzy, so it will likely be hard to make predictions. As the number of clusters increases, classifiers generally decrease in accuracy.\n",
    "\n",
    "<li> Nothing is linearly correlated with the target (hotel_clusters), meaning we can’t use fast machine learning techniques like linear regression.\n",
    "\n",
    "\n",
    "For these reasons, machine learning probably won’t work well on our data, but we can try an algorithm and find out.\n",
    "\n",
    "<b> Generating features</b>\n",
    "\n",
    "The first step in applying machine learning is to generate features. We can generate features using both what’s available in the training data, and what’s available in destinations. We haven’t looked at destinations yet, so let’s take a quick peek.\n",
    "\n",
    "<b> Generating features from destinations</b>\n",
    "\n",
    "Destinations contains an id that corresponds to srch_destination_id, along with 149 columns of latent information about that destination. Here’s a sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_destination_id</th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "      <th>d4</th>\n",
       "      <th>d5</th>\n",
       "      <th>d6</th>\n",
       "      <th>d7</th>\n",
       "      <th>d8</th>\n",
       "      <th>d9</th>\n",
       "      <th>...</th>\n",
       "      <th>d140</th>\n",
       "      <th>d141</th>\n",
       "      <th>d142</th>\n",
       "      <th>d143</th>\n",
       "      <th>d144</th>\n",
       "      <th>d145</th>\n",
       "      <th>d146</th>\n",
       "      <th>d147</th>\n",
       "      <th>d148</th>\n",
       "      <th>d149</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-1.897627</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-1.897627</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.082564</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.165028</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.031597</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.165028</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.165028</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.165028</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-2.183490</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.189562</td>\n",
       "      <td>-2.105819</td>\n",
       "      <td>-2.075407</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.118483</td>\n",
       "      <td>-2.140393</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.196379</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.192009</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.057548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.115485</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.161081</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-2.189562</td>\n",
       "      <td>-2.187783</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.171153</td>\n",
       "      <td>-2.152303</td>\n",
       "      <td>-2.056618</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.145911</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.187356</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.191779</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.185161</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.188037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   srch_destination_id        d1        d2        d3        d4        d5  \\\n",
       "0                    0 -2.198657 -2.198657 -2.198657 -2.198657 -2.198657   \n",
       "1                    1 -2.181690 -2.181690 -2.181690 -2.082564 -2.181690   \n",
       "2                    2 -2.183490 -2.224164 -2.224164 -2.189562 -2.105819   \n",
       "3                    3 -2.177409 -2.177409 -2.177409 -2.177409 -2.177409   \n",
       "4                    4 -2.189562 -2.187783 -2.194008 -2.171153 -2.152303   \n",
       "\n",
       "         d6        d7        d8        d9    ...         d140      d141  \\\n",
       "0 -1.897627 -2.198657 -2.198657 -1.897627    ...    -2.198657 -2.198657   \n",
       "1 -2.165028 -2.181690 -2.181690 -2.031597    ...    -2.165028 -2.181690   \n",
       "2 -2.075407 -2.224164 -2.118483 -2.140393    ...    -2.224164 -2.224164   \n",
       "3 -2.115485 -2.177409 -2.177409 -2.177409    ...    -2.161081 -2.177409   \n",
       "4 -2.056618 -2.194008 -2.194008 -2.145911    ...    -2.187356 -2.194008   \n",
       "\n",
       "       d142      d143      d144      d145      d146      d147      d148  \\\n",
       "0 -2.198657 -2.198657 -2.198657 -2.198657 -2.198657 -2.198657 -2.198657   \n",
       "1 -2.165028 -2.181690 -2.181690 -2.165028 -2.181690 -2.181690 -2.181690   \n",
       "2 -2.196379 -2.224164 -2.192009 -2.224164 -2.224164 -2.224164 -2.224164   \n",
       "3 -2.177409 -2.177409 -2.177409 -2.177409 -2.177409 -2.177409 -2.177409   \n",
       "4 -2.191779 -2.194008 -2.194008 -2.185161 -2.194008 -2.194008 -2.194008   \n",
       "\n",
       "       d149  \n",
       "0 -2.198657  \n",
       "1 -2.181690  \n",
       "2 -2.057548  \n",
       "3 -2.177409  \n",
       "4 -2.188037  \n",
       "\n",
       "[5 rows x 150 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destinations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The competition doesn’t tell us exactly what each latent feature is, but it’s safe to assume that it’s some combination of destination characteristics, like name, description, and more. These latent features were converted to numbers, so they could be anonymized.\n",
    "\n",
    "We can use the destination information as features in a machine learning algorithm, but we’ll need to compress the number of columns down first, to minimize runtime. We can use PCA to do this. PCA will reduce the number of columns in a matrix while trying to preserve the same amount of variance per row. Ideally, PCA will compress all the information contained in all the columns into less, but in practice, some information is lost.\n",
    "\n",
    "In the code below, we:\n",
    "\n",
    "<ul>\n",
    "<li> Initialize a PCA model using scikit-learn.\n",
    "<li> Specify that we want to only have 3 columns in our data.\n",
    "<li> Transform the columns d1-d149 into 3 columns.\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 'srch_destination_id']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "# we skip the srch_destination_id from dimensionality reduction because we might need to extract it later\n",
    "dest_small = pca.fit_transform(destinations[[\"d{0}\".format(i + 1) for i in range(149)]])\n",
    "dest_small = pd.DataFrame(dest_small)\n",
    "#now we apply the srch_destination_id to our dimension reduced data\n",
    "dest_small[\"srch_destination_id\"] = destinations[\"srch_destination_id\"]\n",
    "#lets see the column names\n",
    "print(dest_small.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code compresses the 149 columns in destinations down to 3 columns, and creates a new DataFrame called dest_small. We preserve most of the variance in destinations while doing this, so we don’t lose a lot of information, but save a lot of runtime for a machine learning algorithm.\n",
    "\n",
    "<b>Generating features</b>\n",
    "\n",
    "Now that the preliminaries are done with, we can generate our features. We’ll do the following:\n",
    "\n",
    "<ul>\n",
    "\n",
    "<li> Generate new date features based on date_time, srch_ci, and srch_co.\n",
    "<li> Remove non-numeric columns like date_time.\n",
    "<li> Add in features from dest_small.\n",
    "<li> Replace any missing values with -1.\n",
    "</ul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date_time' 'site_name' 'posa_continent' 'user_location_country'\n",
      " 'user_location_region' 'user_location_city' 'orig_destination_distance'\n",
      " 'user_id' 'is_mobile' 'is_package' 'channel' 'srch_ci' 'srch_co'\n",
      " 'srch_adults_cnt' 'srch_children_cnt' 'srch_rm_cnt' 'srch_destination_id'\n",
      " 'srch_destination_type_id' 'is_booking' 'cnt' 'hotel_continent'\n",
      " 'hotel_country' 'hotel_market' 'hotel_cluster' 'year' 'month']\n",
      "['id' 'date_time' 'site_name' 'posa_continent' 'user_location_country'\n",
      " 'user_location_region' 'user_location_city' 'orig_destination_distance'\n",
      " 'user_id' 'is_mobile' 'is_package' 'channel' 'srch_ci' 'srch_co'\n",
      " 'srch_adults_cnt' 'srch_children_cnt' 'srch_rm_cnt' 'srch_destination_id'\n",
      " 'srch_destination_type_id' 'hotel_continent' 'hotel_country'\n",
      " 'hotel_market']\n"
     ]
    }
   ],
   "source": [
    "#lets review the columns in train and test set\n",
    "print(train.columns.values)\n",
    "print(test.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['channel' 'ci_day' 'ci_dayofweek' 'ci_month' 'ci_quarter' 'cnt' 'co_day'\n",
      " 'co_dayofweek' 'co_month' 'co_quarter' 'day' 'dayofweek' 'hotel_cluster'\n",
      " 'hotel_continent' 'hotel_country' 'hotel_market' 'hour' 'is_booking'\n",
      " 'is_mobile' 'is_package' 'minute' 'month' 'orig_destination_distance'\n",
      " 'posa_continent' 'quarter' 'site_name' 'srch_adults_cnt'\n",
      " 'srch_children_cnt' 'srch_destination_id' 'srch_destination_type_id'\n",
      " 'srch_rm_cnt' 'stay_span' 'user_id' 'user_location_city'\n",
      " 'user_location_country' 'user_location_region' 'year' 0 1 2]\n"
     ]
    }
   ],
   "source": [
    "def calc_fast_features(df):\n",
    "    df[\"date_time\"] = pd.to_datetime(df[\"date_time\"])\n",
    "    df[\"srch_ci\"] = pd.to_datetime(df[\"srch_ci\"], format='%Y-%m-%d', errors=\"coerce\")\n",
    "    df[\"srch_co\"] = pd.to_datetime(df[\"srch_co\"], format='%Y-%m-%d', errors=\"coerce\")\n",
    "    \n",
    "    props = {}\n",
    "    for prop in [\"month\", \"day\", \"hour\", \"minute\", \"dayofweek\", \"quarter\"]:\n",
    "        props[prop] = getattr(df[\"date_time\"].dt, prop)\n",
    "    \n",
    "    carryover = [p for p in df.columns if p not in [\"date_time\", \"srch_ci\", \"srch_co\"]]\n",
    "    for prop in carryover:\n",
    "        props[prop] = df[prop]\n",
    "    \n",
    "    date_props = [\"month\", \"day\", \"dayofweek\", \"quarter\"]\n",
    "    for prop in date_props:\n",
    "        props[\"ci_{0}\".format(prop)] = getattr(df[\"srch_ci\"].dt, prop)\n",
    "        props[\"co_{0}\".format(prop)] = getattr(df[\"srch_co\"].dt, prop)\n",
    "    props[\"stay_span\"] = (df[\"srch_co\"] - df[\"srch_ci\"]).astype('timedelta64[h]')\n",
    "        \n",
    "    ret = pd.DataFrame(props)\n",
    "    \n",
    "    ret = ret.join(dest_small, on=\"srch_destination_id\", how='left', rsuffix=\"dest\")\n",
    "    ret = ret.drop(\"srch_destination_iddest\", axis=1)\n",
    "    return ret\n",
    "\n",
    "df = calc_fast_features(t1)\n",
    "df.fillna(-1, inplace=True)\n",
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above will calculate features such as length of stay, check in day, and check out month. These features will help us train a machine learning algorithm later on.\n",
    "\n",
    "Replacing missing values with -1 isn’t the best choice, but it will work fine for now, and we can always optimize the behavior later on.\n",
    "\n",
    "\n",
    "<b> Machine learning</b>\n",
    "\n",
    "Now that we have features for our training data, we can try machine learning. We’ll use 3-fold cross validation across the training set to generate a reliable error estimate. Cross validation splits the training set up into 3 parts, then predicts hotel_cluster for each part using the other parts to train with.\n",
    "\n",
    "We’ll generate predictions using the Random Forest algorithm. Random forests build trees, which can fit to nonlinear tendencies in data. This will enable us to make predictions, even though none of our columns are linearly related.\n",
    "\n",
    "We’ll first initialize the model and compute cross validation scores:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.06260304,  0.06737546,  0.06583448])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = [c for c in df.columns if c not in [\"hotel_cluster\"]]\n",
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10, min_weight_fraction_leaf=0.1)\n",
    "scores = cross_validation.cross_val_score(clf, df[predictors], df['hotel_cluster'], cv=3)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The above code doesn’t give us very good accuracy, and confirms our original suspicion that machine learning isn’t a great approach to this problem. However, classifiers tend to have lower accuracy when there is a high cluster count. We can instead try training 100 binary classifiers. Each classifier will just determine if a row is in it’s cluster, or not. This will entail training one classifier per label in hotel_cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b> Binary classifiers</b>\n",
    "\n",
    "We’ll again train Random Forests, but each forest will predict only a single hotel cluster. We’ll use 2 fold cross validation for speed, and only train 10 trees per label.\n",
    "\n",
    "In the code below, we:\n",
    "\n",
    "<ul>\n",
    "\n",
    "<li> Loop across each unique hotel_cluster.\n",
    "<ul>\n",
    "    <li> Train a Random Forest classifier using 2-fold cross validation.\n",
    "    <li> Extract the probabilities from the classifier that the row is in the unique hotel_cluster\n",
    "</ul>\n",
    "<li> Combine all the probabilities.\n",
    "<li> For each row, find the 5 largest probabilities, and assign those hotel_cluster values as predictions.\n",
    "<li> Compute accuracy using mapk.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n",
      "[100030 100031 100032 ..., 200057 200058 200059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbara012.AD.004\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100030 100031 100032 ..., 200057 200058 200059]\n",
      "[     0      1      2 ..., 100027 100028 100029]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import KFold\n",
    "from itertools import chain\n",
    "\n",
    "all_probs = []\n",
    "unique_clusters = df[\"hotel_cluster\"].unique()\n",
    "for cluster in unique_clusters:\n",
    "    df[\"target\"] = 1\n",
    "    df[\"target\"][df[\"hotel_cluster\"] != cluster] = 0\n",
    "    predictors = [col for col in df if col not in ['hotel_cluster', \"target\"]]\n",
    "    probs = []\n",
    "    cv = KFold(len(df[\"target\"]), n_folds=2)\n",
    "    clf = RandomForestClassifier(n_estimators=10, min_weight_fraction_leaf=0.1)\n",
    "    for i, (tr, te) in enumerate(cv):\n",
    "        print(tr)\n",
    "        print(te)\n",
    "        #print(df[predictors].iloc[tr])\n",
    "        clf.fit(df[predictors].iloc[tr], df[\"target\"].iloc[tr])\n",
    "        preds = clf.predict_proba(df[predictors].iloc[te])\n",
    "        probs.append([p[1] for p in preds])\n",
    "    full_probs = chain.from_iterable(probs)\n",
    "    all_probs.append(list(full_probs))\n",
    "\n",
    "prediction_frame = pd.DataFrame(all_probs).T\n",
    "prediction_frame.columns = unique_clusters\n",
    "def find_top_5(row):\n",
    "    return list(row.nlargest(5).index)\n",
    "\n",
    "preds = []\n",
    "for index, row in prediction_frame.iterrows():\n",
    "    preds.append(find_top_5(row))\n",
    "\n",
    "mapk([[l] for l in t2.iloc[\"hotel_cluster\"]], preds, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>References </b>\n",
    "\n",
    "A post from Vik Paruchuri  at https://www.dataquest.io/blog/kaggle-tutorial/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
